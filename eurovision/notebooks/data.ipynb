{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eurovision Song Contest Data\n",
    "\n",
    "This notebook imports all the data required to visualise and model trends in the Eurovision voting.\n",
    "The data imported is from the following sources:\n",
    "\n",
    "- Voting Scores\n",
    "    - 1975-2019 data from [Kaggle](https://www.kaggle.com/datasets/datagraver/eurovision-song-contest-scores-19752019)\n",
    "    - 2020 was cancelled\n",
    "    - 2021, 2022 scraped from Wikipedia\n",
    "    - We limit to 1998 onwards because this is when the voting changed to include tele-voting.\n",
    "- Song and country languages\n",
    "    - Performance language from [Kaggle](https://www.kaggle.com/datasets/minitree/eurovision-song-lyrics?select=eurovision-lyrics-2022.json)\n",
    "    - Official country language from [wikipedia](https://en.wikipedia.org/wiki/List_of_official_languages_by_country_and_territory)\n",
    "- Gender\n",
    "    - The gender data is guessed by scraping the wikipedia page for the performing artist\n",
    "- Migration data between performing and voting countries\n",
    "    - [Our World in Data](https://ourworldindata.org/migration) on international migration, under the 'Explore data on where people migrate from and to' section.\n",
    "       Original source is from the UN. Data shows total number of immigrants in each country split by country of origin in the years 1990-2020, recorded at intervals of every 5 years.\n",
    "    - Country populations are from the [World Bank](https://data.worldbank.org/indicator/SP.POP.TOTL?end=2021&start=2021&view=map).\n",
    "- Country borders\n",
    "    - [GeoDataSource](https://github.com/geodatasource/country-borders/)   \n",
    "- Competition winners\n",
    "    - [Wikipedia](https://en.wikipedia.org/wiki/List_of_Eurovision_Song_Contest_winners)\n",
    "- 2023 performers\n",
    "    - [Wikipedia](https://en.wikipedia.org/wiki/Eurovision_Song_Contest_2023)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting scores\n",
    "\n",
    "We import the voting scores from a variety of sources: \n",
    " - 1975-2019 data from Kaggle: https://www.kaggle.com/datasets/datagraver/eurovision-song-contest-scores-19752019\n",
    " - 2020 was cancelled\n",
    " - 2021, 2022 scraped from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pycountry\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49832, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>(semi-)_final</th>\n",
       "      <th>edition</th>\n",
       "      <th>jury_or_televoting</th>\n",
       "      <th>from_country</th>\n",
       "      <th>to_country</th>\n",
       "      <th>points</th>\n",
       "      <th>duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975</td>\n",
       "      <td>f</td>\n",
       "      <td>1975f</td>\n",
       "      <td>J</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>f</td>\n",
       "      <td>1975f</td>\n",
       "      <td>J</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Finland</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975</td>\n",
       "      <td>f</td>\n",
       "      <td>1975f</td>\n",
       "      <td>J</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>France</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1975</td>\n",
       "      <td>f</td>\n",
       "      <td>1975f</td>\n",
       "      <td>J</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975</td>\n",
       "      <td>f</td>\n",
       "      <td>1975f</td>\n",
       "      <td>J</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year (semi-)_final edition jury_or_televoting from_country to_country  \\\n",
       "0  1975             f   1975f                  J      Belgium    Belgium   \n",
       "1  1975             f   1975f                  J      Belgium    Finland   \n",
       "2  1975             f   1975f                  J      Belgium     France   \n",
       "3  1975             f   1975f                  J      Belgium    Germany   \n",
       "4  1975             f   1975f                  J      Belgium    Ireland   \n",
       "\n",
       "   points duplicate  \n",
       "0       0         x  \n",
       "1       0       NaN  \n",
       "2       2       NaN  \n",
       "3       0       NaN  \n",
       "4      12       NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read in data from the kaggle dataset\n",
    "votes_1975_2019 = pd.read_excel(\"../../data/eurovision_song_contest_1975_2019.xlsx\")\n",
    "\n",
    "# Clean up column names first\n",
    "votes_1975_2019.columns = [c.strip().lower().replace(' ', '_') for c in votes_1975_2019.columns.values.tolist()]\n",
    "\n",
    "print(votes_1975_2019.shape)\n",
    "votes_1975_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>from_country</th>\n",
       "      <th>to_country</th>\n",
       "      <th>points</th>\n",
       "      <th>jury_or_televoting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27422</th>\n",
       "      <td>2011</td>\n",
       "      <td>san marino</td>\n",
       "      <td>austria</td>\n",
       "      <td>0</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13354</th>\n",
       "      <td>2003</td>\n",
       "      <td>israel</td>\n",
       "      <td>romania</td>\n",
       "      <td>6</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12005</th>\n",
       "      <td>2001</td>\n",
       "      <td>denmark</td>\n",
       "      <td>norway</td>\n",
       "      <td>0</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43410</th>\n",
       "      <td>2018</td>\n",
       "      <td>romania</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>0</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47857</th>\n",
       "      <td>2019</td>\n",
       "      <td>hungary</td>\n",
       "      <td>iceland</td>\n",
       "      <td>12</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12990</th>\n",
       "      <td>2002</td>\n",
       "      <td>switzerland</td>\n",
       "      <td>greece</td>\n",
       "      <td>0</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43788</th>\n",
       "      <td>2018</td>\n",
       "      <td>azerbaijan</td>\n",
       "      <td>ireland</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36989</th>\n",
       "      <td>2016</td>\n",
       "      <td>latvia</td>\n",
       "      <td>austria</td>\n",
       "      <td>4</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26806</th>\n",
       "      <td>2011</td>\n",
       "      <td>bulgaria</td>\n",
       "      <td>greece</td>\n",
       "      <td>10</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42968</th>\n",
       "      <td>2018</td>\n",
       "      <td>france</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>0</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year from_country to_country  points jury_or_televoting\n",
       "27422  2011   san marino    austria       0                  J\n",
       "13354  2003       israel    romania       6                  J\n",
       "12005  2001      denmark     norway       0                  J\n",
       "43410  2018      romania    ukraine       0                  J\n",
       "47857  2019      hungary    iceland      12                  T\n",
       "12990  2002  switzerland     greece       0                  J\n",
       "43788  2018   azerbaijan    ireland       0                  T\n",
       "36989  2016       latvia    austria       4                  T\n",
       "26806  2011     bulgaria     greece      10                  J\n",
       "42968  2018       france    ukraine       0                  J"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clean up this dataset.\n",
    "\n",
    "# Select only finals votes, and only 1998 onwards (inclusive)\n",
    "votes_1998_2019 = votes_1975_2019[(votes_1975_2019['(semi-)_final'] == 'f') & (votes_1975_2019['year'] >= 1998)]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "votes_1998_2019 = votes_1998_2019[[\"year\", \"from_country\", \"to_country\", \"points\", \"jury_or_televoting\"]]\n",
    "\n",
    "# Clean up country names\n",
    "def standardise_country(c):\n",
    "    replacements = [('-', ' '), ('&', 'and'), ('netherands', 'netherlands'),\n",
    "                    # FYR Macedonia was formally renamed as North Macedonia in 2019\n",
    "                    ('f.y.r. macedonia', 'north macedonia'), \n",
    "                    ('russia', 'russian federation'), \n",
    "                    ('the netherlands', 'netherlands'), \n",
    "                    ('czech republic', 'czechia'),\n",
    "                    # Yugoslavia dissolved in 2002; most of it became 'Serbia and Montenegro', until 2006, when Serbia and Montenegro split ways.\n",
    "                    ('serbia and montenegro', 'yugoslavia'),\n",
    "                    ('moldova', 'moldova, republic of')]\n",
    "    c = c.lower()\n",
    "    for r in replacements:\n",
    "        c = c.replace(r[0], r[1])\n",
    "    return c\n",
    "\n",
    "for column in ['from_country', 'to_country']:\n",
    "    votes_1998_2019[column] = votes_1998_2019[column].map(standardise_country)\n",
    "\n",
    "# Drop columns which correspond to the same vote (there are two Belarus -> Russia in 2019, for example)\n",
    "votes_1998_2019 = votes_1998_2019.drop_duplicates(subset=['year', 'from_country', 'to_country', 'jury_or_televoting'])\n",
    "\n",
    "# Drop Lithuania in 2003 (they didn't participate - I don't know why it's still in the dataset)\n",
    "votes_1998_2019 = votes_1998_2019[~((votes_1998_2019['to_country'] == 'lithuania') & (votes_1998_2019['year'] == 2003))]\n",
    "\n",
    "# Drop \"votes\" from one country to itself\n",
    "votes_1998_2019 = votes_1998_2019[votes_1998_2019['from_country'] != votes_1998_2019['to_country']]\n",
    "\n",
    "votes_1998_2019.sample(n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>from_country</th>\n",
       "      <th>to_country</th>\n",
       "      <th>points</th>\n",
       "      <th>jury_or_televoting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10866</th>\n",
       "      <td>1999</td>\n",
       "      <td>belgium</td>\n",
       "      <td>bosnia and herzegovina</td>\n",
       "      <td>1</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25823</th>\n",
       "      <td>2010</td>\n",
       "      <td>sweden</td>\n",
       "      <td>israel</td>\n",
       "      <td>0</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12254</th>\n",
       "      <td>2001</td>\n",
       "      <td>norway</td>\n",
       "      <td>israel</td>\n",
       "      <td>0</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23328</th>\n",
       "      <td>2009</td>\n",
       "      <td>bosnia and herzegovina</td>\n",
       "      <td>turkey</td>\n",
       "      <td>7</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27237</th>\n",
       "      <td>2011</td>\n",
       "      <td>lithuania</td>\n",
       "      <td>moldova, republic of</td>\n",
       "      <td>4</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31024</th>\n",
       "      <td>2013</td>\n",
       "      <td>moldova, republic of</td>\n",
       "      <td>iceland</td>\n",
       "      <td>0</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35704</th>\n",
       "      <td>2016</td>\n",
       "      <td>france</td>\n",
       "      <td>hungary</td>\n",
       "      <td>0</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34586</th>\n",
       "      <td>2015</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>austria</td>\n",
       "      <td>0</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42774</th>\n",
       "      <td>2018</td>\n",
       "      <td>croatia</td>\n",
       "      <td>ireland</td>\n",
       "      <td>3</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40780</th>\n",
       "      <td>2017</td>\n",
       "      <td>portugal</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>3</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year            from_country              to_country  points  \\\n",
       "10866  1999                 belgium  bosnia and herzegovina       1   \n",
       "25823  2010                  sweden                  israel       0   \n",
       "12254  2001                  norway                  israel       0   \n",
       "23328  2009  bosnia and herzegovina                  turkey       7   \n",
       "27237  2011               lithuania    moldova, republic of       4   \n",
       "31024  2013    moldova, republic of                 iceland       0   \n",
       "35704  2016                  france                 hungary       0   \n",
       "34586  2015          united kingdom                 austria       0   \n",
       "42774  2018                 croatia                 ireland       3   \n",
       "40780  2017                portugal                 ukraine       3   \n",
       "\n",
       "      jury_or_televoting  \n",
       "10866                  J  \n",
       "25823                  J  \n",
       "12254                  J  \n",
       "23328                  J  \n",
       "27237                  J  \n",
       "31024                  J  \n",
       "35704                  J  \n",
       "34586                  J  \n",
       "42774                  J  \n",
       "40780                  T  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now we need to fetch some data from Wikipedia for the 2021 and 2022 contests.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def import_votes_from_wp(year: int) -> pd.DataFrame:\n",
    "    # ID numbers for the respective tables on the Wikipedia page.\n",
    "    JURY_ID = 16\n",
    "    TELEVOTING_ID = 17\n",
    "\n",
    "    url = f\"https://en.wikipedia.org/wiki/Eurovision_Song_Contest_{year}#Final_2\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    tables = soup.find_all('table', {'class': \"wikitable\"})\n",
    "\n",
    "    def parse_table_from_id(wp_id: int, jury_or_tele: str) -> pd.DataFrame:\n",
    "        df_table = pd.read_html(str(tables[wp_id]))\n",
    "        df_table = pd.DataFrame(df_table[0])\n",
    "\n",
    "        # remove redundant rows/columns\n",
    "        df_table = df_table.drop(df_table.columns[[0, 2, 3, 4]], axis=1)\n",
    "        df_table = df_table.drop(df_table.index[[0, 2]], axis=0) \n",
    "\n",
    "        # set the index to the first column\n",
    "        df_table = df_table.set_index(df_table.columns[0])\n",
    "\n",
    "        # set the column names as the first row\n",
    "        df_table.columns = df_table.iloc[0]\n",
    "        df_table = df_table.drop(df_table.index[0])\n",
    "\n",
    "        # replace NaN with 0\n",
    "        df_table = df_table.fillna(0)\n",
    "\n",
    "        # squash the column index with stack\n",
    "        df_table = df_table.stack().reset_index()\n",
    "\n",
    "        df_table.columns = ['to_country', 'from_country', 'points']\n",
    "        df_table['jury_or_televoting'] = jury_or_tele\n",
    "\n",
    "        df_table['year'] = year\n",
    "\n",
    "        # re-order the columns to match the original data   \n",
    "        df_table = df_table[['year', 'from_country', 'to_country', 'points', 'jury_or_televoting']]\n",
    "        \n",
    "        df_table['points'] = df_table['points'].astype(int)\n",
    "        \n",
    "        # Clean up countries as before\n",
    "        for column in ['from_country', 'to_country']:\n",
    "            df_table[column] = df_table[column].map(standardise_country)\n",
    "\n",
    "        return(df_table)\n",
    "\n",
    "    jury_table = parse_table_from_id(JURY_ID, jury_or_tele='J')\n",
    "    tele_table = parse_table_from_id(TELEVOTING_ID, jury_or_tele='T')\n",
    "    return(pd.concat([jury_table, tele_table]))\n",
    "\n",
    "votes_1998_2022 = pd.concat([votes_1998_2019,\n",
    "                             import_votes_from_wp(2021),\n",
    "                             import_votes_from_wp(2022)])\n",
    "\n",
    "# Again, drop \"votes\" from one country to herself\n",
    "votes_1998_2022 = votes_1998_2022[votes_1998_2022['from_country'] != votes_1998_2022['to_country']]\n",
    "\n",
    "votes_1998_2022.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All years are consistent!\n"
     ]
    }
   ],
   "source": [
    "# This cell is a sanity check to make sure that all countries participating in \n",
    "# a given year got the same number of votes. We hope to see the 'is_consistent' \n",
    "# column be True for all years in the output.\n",
    "\n",
    "def check_consistency(df):\n",
    "    def all_entries_same(arr : np.ndarray) -> bool:\n",
    "        # Determines if all non-NaN entries in a numpy array have the same value.\n",
    "        arr2 = arr[~np.isnan(arr)]\n",
    "        return np.all(arr2 == arr2[0])\n",
    "\n",
    "    # Pivot to wide form, so that each row gives the number of scores each country received in a given year\n",
    "    grouped_votes = df.groupby(by=['year', 'to_country'])['points'].count().reset_index()\n",
    "    grouped_votes = grouped_votes.pivot(index=\"year\", columns=\"to_country\", values=\"points\")\n",
    "    # Create \"is_consistent\" column and move it to the front\n",
    "    col_names = grouped_votes.columns\n",
    "    grouped_votes[\"is_consistent\"] = grouped_votes.apply(all_entries_same, axis=1, raw=True)\n",
    "    new_col_names = [\"is_consistent\", *col_names]\n",
    "\n",
    "    if(not all(grouped_votes[\"is_consistent\"])):     \n",
    "        # Show data\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "            display(grouped_votes.reindex(columns=new_col_names))\n",
    "\n",
    "        raise Exception(\"Inconsistent number of votes received by countries in some years!\")\n",
    "    else: \n",
    "        print(\"All years are consistent!\")\n",
    "        \n",
    "check_consistency(votes_1998_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to combine jury and televoting scores.\n",
    "\n",
    "# Years where jury voting happened\n",
    "jury_years = np.unique(votes_1998_2022[votes_1998_2022['jury_or_televoting'] == 'J']['year'])\n",
    "# Years where televoting happened\n",
    "televoting_years = np.unique(votes_1998_2022[votes_1998_2022['jury_or_televoting'] == 'T']['year'])\n",
    "# Years where both happened (i.e. the intersection)\n",
    "double_voting_years = np.intersect1d(jury_years, televoting_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>from_country</th>\n",
       "      <th>to_country</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>armenia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>australia</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>austria</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>azerbaijan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>belgium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year from_country  to_country  points\n",
       "0  2016      albania     armenia       0\n",
       "1  2016      albania   australia      12\n",
       "2  2016      albania     austria       0\n",
       "3  2016      albania  azerbaijan       0\n",
       "4  2016      albania     belgium       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the years for which the points can just be used as-is.\n",
    "votes_to_keep = votes_1998_2022[~votes_1998_2022['year'].isin(double_voting_years)]\n",
    "votes_to_keep = votes_to_keep.drop(columns=['jury_or_televoting'])\n",
    "\n",
    "# These are the years which we need to process.\n",
    "# The way we do this is to add up the J and T scores, then re-rank them and assign 12 points to the highest score, 10 to the next-highest, etc.\n",
    "votes_to_process = votes_1998_2022[votes_1998_2022['year'].isin(double_voting_years)]\n",
    "summed_votes = votes_to_process.sort_values(by=['year', 'from_country', 'to_country'])\n",
    "summed_votes = summed_votes.groupby(by=['year', 'from_country', 'to_country']).sum(numeric_only=True)\n",
    "\n",
    "def rescale_points(pts: pd.Series) -> pd.Series:\n",
    "    # grp is a pd.Series corresponding to one combination of 'year' and 'from_country'\n",
    "    ranks_to_rescaled_points = {1: 12, 2: 10, 3: 8, 4: 7, 5: 6, 6: 5, 7: 4, 8: 3, 9: 2, 10: 1}\n",
    "    ranks = [sorted(pts, reverse=True).index(pt) + 1 for pt in pts]\n",
    "    rescaled_points = {pt: ranks_to_rescaled_points.get(r, 0) for pt, r in zip(pts, ranks)}\n",
    "    return pts.map(rescaled_points)\n",
    "\n",
    "processed_votes = summed_votes.groupby(by=['year', 'from_country']).transform(rescale_points).reset_index()\n",
    "processed_votes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>from_country</th>\n",
       "      <th>to_country</th>\n",
       "      <th>points</th>\n",
       "      <th>rescaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>australia</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>italy</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>russian federation</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>bulgaria</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>france</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>spain</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>poland</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>lithuania</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>sweden</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>israel</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>hungary</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>malta</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>armenia</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>georgia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>latvia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>czechia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>netherlands</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>cyprus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>croatia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>serbia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>belgium</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>azerbaijan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>albania</td>\n",
       "      <td>austria</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year from_country          to_country  points  rescaled\n",
       "1   2016      albania           australia      24        12\n",
       "14  2016      albania               italy      18        10\n",
       "20  2016      albania  russian federation      14         8\n",
       "5   2016      albania            bulgaria      12         7\n",
       "9   2016      albania              france      10         6\n",
       "24  2016      albania             ukraine       6         5\n",
       "22  2016      albania               spain       6         5\n",
       "25  2016      albania      united kingdom       5         3\n",
       "19  2016      albania              poland       5         3\n",
       "16  2016      albania           lithuania       4         1\n",
       "23  2016      albania              sweden       3         0\n",
       "13  2016      albania              israel       3         0\n",
       "12  2016      albania             hungary       2         0\n",
       "17  2016      albania               malta       2         0\n",
       "0   2016      albania             armenia       2         0\n",
       "11  2016      albania             germany       0         0\n",
       "10  2016      albania             georgia       0         0\n",
       "15  2016      albania              latvia       0         0\n",
       "8   2016      albania             czechia       0         0\n",
       "18  2016      albania         netherlands       0         0\n",
       "7   2016      albania              cyprus       0         0\n",
       "6   2016      albania             croatia       0         0\n",
       "21  2016      albania              serbia       0         0\n",
       "4   2016      albania             belgium       0         0\n",
       "3   2016      albania          azerbaijan       0         0\n",
       "2   2016      albania             austria       0         0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "x = processed_votes.rename(columns={\"points\": \"rescaled\"})\n",
    "x = x.set_index([\"year\", \"from_country\", \"to_country\"])\n",
    "v = summed_votes.reset_index().set_index([\"year\", \"from_country\", \"to_country\"])\n",
    "joined = v.join(x, how=\"outer\").reset_index()\n",
    "joined[(joined['year'] == 2016) & (joined['from_country'] == 'albania')].sort_values(by=\"points\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>from_country</th>\n",
       "      <th>to_country</th>\n",
       "      <th>points</th>\n",
       "      <th>from_code2</th>\n",
       "      <th>from_code3</th>\n",
       "      <th>to_code2</th>\n",
       "      <th>to_code3</th>\n",
       "      <th>total_points</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>belgium</td>\n",
       "      <td>croatia</td>\n",
       "      <td>5</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>HR</td>\n",
       "      <td>HRV</td>\n",
       "      <td>131</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>belgium</td>\n",
       "      <td>cyprus</td>\n",
       "      <td>2</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>CY</td>\n",
       "      <td>CYP</td>\n",
       "      <td>37</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>belgium</td>\n",
       "      <td>estonia</td>\n",
       "      <td>0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>EE</td>\n",
       "      <td>EST</td>\n",
       "      <td>36</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>belgium</td>\n",
       "      <td>north macedonia</td>\n",
       "      <td>0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>MK</td>\n",
       "      <td>MKD</td>\n",
       "      <td>16</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>belgium</td>\n",
       "      <td>finland</td>\n",
       "      <td>0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>FI</td>\n",
       "      <td>FIN</td>\n",
       "      <td>22</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21305</th>\n",
       "      <td>2022</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>serbia</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>RS</td>\n",
       "      <td>SRB</td>\n",
       "      <td>169</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21306</th>\n",
       "      <td>2022</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>spain</td>\n",
       "      <td>8</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>ES</td>\n",
       "      <td>ESP</td>\n",
       "      <td>282</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21307</th>\n",
       "      <td>2022</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>sweden</td>\n",
       "      <td>10</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>SE</td>\n",
       "      <td>SWE</td>\n",
       "      <td>245</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21308</th>\n",
       "      <td>2022</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>switzerland</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>CH</td>\n",
       "      <td>CHE</td>\n",
       "      <td>28</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21309</th>\n",
       "      <td>2022</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>7</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>UA</td>\n",
       "      <td>UKR</td>\n",
       "      <td>379</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21310 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year    from_country       to_country  points from_code2 from_code3  \\\n",
       "0      1998         belgium          croatia       5         BE        BEL   \n",
       "1      1998         belgium           cyprus       2         BE        BEL   \n",
       "2      1998         belgium          estonia       0         BE        BEL   \n",
       "3      1998         belgium  north macedonia       0         BE        BEL   \n",
       "4      1998         belgium          finland       0         BE        BEL   \n",
       "...     ...             ...              ...     ...        ...        ...   \n",
       "21305  2022  united kingdom           serbia       0         GB        GBR   \n",
       "21306  2022  united kingdom            spain       8         GB        GBR   \n",
       "21307  2022  united kingdom           sweden      10         GB        GBR   \n",
       "21308  2022  united kingdom      switzerland       0         GB        GBR   \n",
       "21309  2022  united kingdom          ukraine       7         GB        GBR   \n",
       "\n",
       "      to_code2 to_code3  total_points  rank  \n",
       "0           HR      HRV           131   5.0  \n",
       "1           CY      CYP            37  11.0  \n",
       "2           EE      EST            36  12.0  \n",
       "3           MK      MKD            16  19.0  \n",
       "4           FI      FIN            22  15.0  \n",
       "...        ...      ...           ...   ...  \n",
       "21305       RS      SRB           169   5.0  \n",
       "21306       ES      ESP           282   3.0  \n",
       "21307       SE      SWE           245   4.0  \n",
       "21308       CH      CHE            28  18.0  \n",
       "21309       UA      UKR           379   1.0  \n",
       "\n",
       "[21310 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add in country codes, and that's our final voting data.\n",
    "votes = pd.concat([votes_to_keep, processed_votes]).reset_index(drop=True)\n",
    "\n",
    "def get_country_codes(name):\n",
    "    if name == 'yugoslavia':\n",
    "        # That's how it's encoded in pycountry.\n",
    "        # https://github.com/flyingcircusio/pycountry/blob/main/src/pycountry/databases/iso3166-3.json\n",
    "        cty = pycountry.historic_countries.get(name='yugoslavia, socialist federal republic of')\n",
    "    else:\n",
    "        cty = pycountry.countries.get(name=name)\n",
    "    if cty is None:\n",
    "        raise KeyError(\"Country name \" + name + \" not found in pycountry. This really shouldn't happen.\")\n",
    "    \n",
    "    return cty.alpha_2, cty.alpha_3\n",
    "\n",
    "for ft in ['from', 'to']:\n",
    "    votes[f'{ft}_code2'], votes[f'{ft}_code3'] = zip(*votes[f'{ft}_country'].map(get_country_codes))\n",
    "\n",
    "# Add column for each country and year get the total number of points received\n",
    "votes['total_points'] = votes.groupby(by=['year', 'to_country'])['points'].transform('sum')\n",
    "\n",
    "# For each year rank the countries by total points received, where draws get same value\n",
    "temp = votes[['year', 'to_country', 'total_points']].drop_duplicates()\n",
    "temp['rank'] = temp.groupby(by=['year'])['total_points'].rank(method='first', ascending=False)\n",
    "\n",
    "# merge votes with ranks\n",
    "votes = votes.merge(temp, on=['year', 'to_country', 'total_points'], how='left')\n",
    "\n",
    "\n",
    "votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998 [24]\n",
      "1999 [22]\n",
      "2000 [23]\n",
      "2001 [22]\n",
      "2002 [23]\n",
      "2003 [25 24]\n",
      "2004 [24 23]\n",
      "2005 [24 23]\n",
      "2006 [24 23]\n",
      "2007 [24 23]\n",
      "2008 [25 24]\n",
      "2009 [25 24]\n",
      "2010 [25 24]\n",
      "2011 [25 24]\n",
      "2012 [26 25]\n",
      "2013 [26 25]\n",
      "2014 [26 25]\n",
      "2015 [27 26]\n",
      "2016 [26 25]\n",
      "2017 [26 25]\n",
      "2018 [26 25]\n",
      "2019 [26 25]\n",
      "2021 [26 25]\n",
      "2022 [25 24]\n"
     ]
    }
   ],
   "source": [
    "# sanity check the numbers\n",
    "temp = votes[['from_country', 'year']].value_counts()\n",
    "\n",
    "# for each year print the unique values\n",
    "for year, group in temp.groupby(level=1):\n",
    "    print(year, group.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All years are consistent!\n"
     ]
    }
   ],
   "source": [
    "check_consistency(votes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song language\n",
    "\n",
    "- Performance language from Kaggle: https://www.kaggle.com/datasets/minitree/eurovision-song-lyrics?select=eurovision-lyrics-2022.json\n",
    "- Official country language from wikipedia: https://en.wikipedia.org/wiki/List_of_official_languages_by_country_and_territory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Language_sung</th>\n",
       "      <th>Year</th>\n",
       "      <th>Country_code2</th>\n",
       "      <th>Country_code3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>croatia</td>\n",
       "      <td>Danijela</td>\n",
       "      <td>Croatian</td>\n",
       "      <td>1998</td>\n",
       "      <td>HR</td>\n",
       "      <td>HRV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>greece</td>\n",
       "      <td>Thalassa</td>\n",
       "      <td>Greek</td>\n",
       "      <td>1998</td>\n",
       "      <td>GR</td>\n",
       "      <td>GRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>france</td>\n",
       "      <td>Marie Line</td>\n",
       "      <td>French</td>\n",
       "      <td>1998</td>\n",
       "      <td>FR</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>spain</td>\n",
       "      <td>Mikel Herzog</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1998</td>\n",
       "      <td>ES</td>\n",
       "      <td>ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>switzerland</td>\n",
       "      <td>Gunvor</td>\n",
       "      <td>German</td>\n",
       "      <td>1998</td>\n",
       "      <td>CH</td>\n",
       "      <td>CHE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country        Artist Language_sung  Year Country_code2 Country_code3\n",
       "772      croatia      Danijela      Croatian  1998            HR           HRV\n",
       "773       greece      Thalassa         Greek  1998            GR           GRC\n",
       "774       france    Marie Line        French  1998            FR           FRA\n",
       "775        spain  Mikel Herzog       Spanish  1998            ES           ESP\n",
       "776  switzerland        Gunvor        German  1998            CH           CHE"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs = pd.read_json('../../data/eurovision-lyrics-2022.json').T\n",
    "songs = songs[['Country', 'Artist', 'Language', 'Year']]\n",
    "\n",
    "# Rename a couple of columns\n",
    "songs = songs.rename(columns={'Language': 'Language_sung'})\n",
    "\n",
    "# Tidy up country names\n",
    "for original, replacement in [('Macedonia', 'North Macedonia'),\n",
    "                              ('Russia', 'russian federation'),\n",
    "                              ('Serbia and Montenegro', 'yugoslavia'),\n",
    "                              ('Moldova', 'moldova, republic of'),\n",
    "                              ('Czech Republic', 'czechia'),\n",
    "                              ('The Netherlands', 'netherlands')]:\n",
    "    songs.loc[songs['Country'] == original, 'Country'] = replacement\n",
    "songs['Country'] = songs['Country'].str.lower()\n",
    "\n",
    "# Limit to 1998 and later\n",
    "songs['Year'] = pd.to_numeric(songs['Year'])\n",
    "songs = songs[songs['Year'] > 1997]\n",
    "\n",
    "# Add country code columns\n",
    "songs['Country_code2'], songs['Country_code3'] = zip(\n",
    "    *songs['Country'].map(get_country_codes))\n",
    "\n",
    "songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Language_sung</th>\n",
       "      <th>Year</th>\n",
       "      <th>Country_code2</th>\n",
       "      <th>Country_code3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>romania</td>\n",
       "      <td>WRS</td>\n",
       "      <td>[english, spanish]</td>\n",
       "      <td>2022</td>\n",
       "      <td>RO</td>\n",
       "      <td>ROU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>san marino</td>\n",
       "      <td>Achille Lauro</td>\n",
       "      <td>[italian, english]</td>\n",
       "      <td>2022</td>\n",
       "      <td>SM</td>\n",
       "      <td>SMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>serbia</td>\n",
       "      <td>Konstrakta</td>\n",
       "      <td>[serbian]</td>\n",
       "      <td>2022</td>\n",
       "      <td>RS</td>\n",
       "      <td>SRB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>slovenia</td>\n",
       "      <td>LPS</td>\n",
       "      <td>[slovenian]</td>\n",
       "      <td>2022</td>\n",
       "      <td>SI</td>\n",
       "      <td>SVN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>spain</td>\n",
       "      <td>Chanel</td>\n",
       "      <td>[spanish, english]</td>\n",
       "      <td>2022</td>\n",
       "      <td>ES</td>\n",
       "      <td>ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>sweden</td>\n",
       "      <td>Cornelia Jakobs</td>\n",
       "      <td>[english]</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>SWE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>switzerland</td>\n",
       "      <td>Marius Bear</td>\n",
       "      <td>[english]</td>\n",
       "      <td>2022</td>\n",
       "      <td>CH</td>\n",
       "      <td>CHE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>netherlands</td>\n",
       "      <td>S10</td>\n",
       "      <td>[dutch]</td>\n",
       "      <td>2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>NLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>ukraine</td>\n",
       "      <td>Kalush Orchestra</td>\n",
       "      <td>[ukrainian]</td>\n",
       "      <td>2022</td>\n",
       "      <td>UA</td>\n",
       "      <td>UKR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>united kingdom</td>\n",
       "      <td>Sam Ryder</td>\n",
       "      <td>[english]</td>\n",
       "      <td>2022</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Country            Artist       Language_sung  Year  \\\n",
       "1674         romania               WRS  [english, spanish]  2022   \n",
       "1675      san marino     Achille Lauro  [italian, english]  2022   \n",
       "1676          serbia        Konstrakta           [serbian]  2022   \n",
       "1677        slovenia               LPS         [slovenian]  2022   \n",
       "1678           spain            Chanel  [spanish, english]  2022   \n",
       "1679          sweden   Cornelia Jakobs           [english]  2022   \n",
       "1680     switzerland       Marius Bear           [english]  2022   \n",
       "1681     netherlands               S10             [dutch]  2022   \n",
       "1682         ukraine  Kalush Orchestra         [ukrainian]  2022   \n",
       "1683  united kingdom         Sam Ryder           [english]  2022   \n",
       "\n",
       "     Country_code2 Country_code3  \n",
       "1674            RO           ROU  \n",
       "1675            SM           SMR  \n",
       "1676            RS           SRB  \n",
       "1677            SI           SVN  \n",
       "1678            ES           ESP  \n",
       "1679            SE           SWE  \n",
       "1680            CH           CHE  \n",
       "1681            NL           NLD  \n",
       "1682            UA           UKR  \n",
       "1683            GB           GBR  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tidy up the language sung column\n",
    "songs['Language_sung'] = songs['Language_sung'].str.lower()\n",
    "songs['Language_sung'] = songs['Language_sung'].str.replace('partly|dialect|title|and', '', regex=True)\n",
    "\n",
    "# for each key in the dictionary, replace the value with the key\n",
    "replace_strings = {\n",
    "    'fr\\\\.': 'french', 'eng\\\\.': 'english', 'gr\\\\.': 'greek', \n",
    "    'sp\\\\.': 'spanish', 'rom\\\\.': 'romanian', 'russ\\\\.': 'russian',\n",
    "    'it\\\\.': 'italian', 'germ\\\\.': 'german', 'pol\\\\.': 'polish', \n",
    "    'sign language': 'sign-language'\n",
    "}\n",
    "\n",
    "for key, value in replace_strings.items():\n",
    "    songs['Language_sung'] = songs['Language_sung'].str.replace(key, value, regex=True)\n",
    "\n",
    "def extract_languages(lang_string):\n",
    "    \"\"\"Convert the string in language_sung into a list of languages\"\"\"\n",
    "    langs = re.split(r'\\s*[/()]\\s*', lang_string)\n",
    "    langs = [lang.strip() for lang in langs]\n",
    "    return [lang for lang in langs if lang != \"\"]\n",
    "\n",
    "songs['Language_sung'] = songs['Language_sung'].apply(extract_languages)\n",
    "songs.tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Contains_English  Contains_NonEnglish\n",
       "True              False                  543\n",
       "False             True                   220\n",
       "True              True                   149\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs['Contains_English'] = songs['Language_sung'].apply(lambda x: 'english' in x)\n",
    "songs['Contains_NonEnglish'] = songs['Language_sung'].apply(lambda x: x != ['english'])\n",
    "\n",
    "songs[['Contains_English', 'Contains_NonEnglish']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs containing English or non-English:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Contains_English  Contains_NonEnglish\n",
       "True              False                  543\n",
       "False             True                   220\n",
       "True              True                   149\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of songs containing English or non-English:')\n",
    "\n",
    "songs[['Contains_English', 'Contains_NonEnglish']].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to see whether countries are singing in their official language. We can get the official language from [Wikipedia](https://en.wikipedia.org/wiki/List_of_official_languages_by_country_and_territory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Official_languages</th>\n",
       "      <th>Regional language</th>\n",
       "      <th>Minority language</th>\n",
       "      <th>National language</th>\n",
       "      <th>Widely spoken</th>\n",
       "      <th>Country_code2</th>\n",
       "      <th>Country_code3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>switzerland</td>\n",
       "      <td>french bern fribourg geneva jura neuchâtel val...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CH</td>\n",
       "      <td>CHE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>turkey</td>\n",
       "      <td>turkish</td>\n",
       "      <td></td>\n",
       "      <td>Kurdish</td>\n",
       "      <td>Turkish</td>\n",
       "      <td></td>\n",
       "      <td>TR</td>\n",
       "      <td>TUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>ukraine</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>Russian (Autonomous Republic of Crimea) Crimea...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UA</td>\n",
       "      <td>UKR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>united kingdom</td>\n",
       "      <td>none english has de facto status</td>\n",
       "      <td>Irish and Ulster-Scots (in Northern Ireland) S...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>yugoslavia</td>\n",
       "      <td>serbian montenegrin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YU</td>\n",
       "      <td>YUG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country/Region                                 Official_languages  \\\n",
       "182     switzerland  french bern fribourg geneva jura neuchâtel val...   \n",
       "194          turkey                                            turkish   \n",
       "198         ukraine                                          ukrainian   \n",
       "200  united kingdom                   none english has de facto status   \n",
       "211      yugoslavia                                serbian montenegrin   \n",
       "\n",
       "                                     Regional language Minority language  \\\n",
       "182                                                                        \n",
       "194                                                              Kurdish   \n",
       "198  Russian (Autonomous Republic of Crimea) Crimea...                     \n",
       "200  Irish and Ulster-Scots (in Northern Ireland) S...                     \n",
       "211                                                NaN               NaN   \n",
       "\n",
       "    National language Widely spoken Country_code2 Country_code3  \n",
       "182                                            CH           CHE  \n",
       "194           Turkish                          TR           TUR  \n",
       "198                                            UA           UKR  \n",
       "200                                            GB           GBR  \n",
       "211               NaN           NaN            YU           YUG  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the official languages from Wikipedia\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "url = (\n",
    "    f\"https://en.wikipedia.org/wiki/List_of_official_languages_by_country_and_territory\"\n",
    ")\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "tables = soup.find_all(\"table\", {\"class\": \"wikitable\"})\n",
    "\n",
    "table = tables[0]\n",
    "df_languages = pd.read_html(str(table))\n",
    "df_languages = pd.DataFrame(df_languages[0])\n",
    "\n",
    "# Tidy the columns\n",
    "df_languages = df_languages.fillna(\"\")\n",
    "df_languages[\"Country/Region\"] = df_languages[\"Country/Region\"].apply(\n",
    "    lambda x: re.sub(\"\\[.*?\\]\", \"\", x)\n",
    ")\n",
    "df_languages.rename(columns={\"Official language\": \"Official_languages\"}, inplace=True)\n",
    "df_languages[\"Official_languages\"] = df_languages[\"Official_languages\"].apply(\n",
    "    lambda x: re.sub(\"\\[.*?\\]\", \"\", x)\n",
    ")\n",
    "\n",
    "# Tidy the country names\n",
    "df_languages[\"Country/Region\"] = df_languages[\"Country/Region\"].str.lower()\n",
    "\n",
    "df_languages.loc[\n",
    "    df_languages[\"Country/Region\"] == \"united kingdom and crown dependencies etc.\",\n",
    "    \"Country/Region\",\n",
    "] = \"united kingdom\"\n",
    "df_languages.loc[\n",
    "    df_languages[\"Country/Region\"] == \"russia\", \"Country/Region\"\n",
    "] = \"russian federation\"\n",
    "df_languages.loc[\n",
    "    df_languages[\"Country/Region\"] == \"serbia and montenegro\", \"Country/Region\"\n",
    "] = \"yugoslavia\"\n",
    "df_languages.loc[\n",
    "    df_languages[\"Country/Region\"] == \"moldova\", \"Country/Region\"\n",
    "] = \"moldova, republic of\"\n",
    "df_languages.loc[\n",
    "    df_languages[\"Country/Region\"] == \"czech republic\", \"Country/Region\"\n",
    "] = \"czechia\"\n",
    "df_languages = pd.concat(\n",
    "    [\n",
    "        df_languages,\n",
    "        pd.Series(\n",
    "            {\n",
    "                \"Country/Region\": \"yugoslavia\",\n",
    "                \"Official_languages\": \"serbian montenegrin\",\n",
    "            }\n",
    "        )\n",
    "        .to_frame()\n",
    "        .T,\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "set(songs[\"Country\"].unique()) - set(df_languages[\"Country/Region\"].unique())\n",
    "\n",
    "df_languages = df_languages.loc[df_languages[\"Country/Region\"].isin(songs[\"Country\"].unique())]\n",
    "\n",
    "df_languages[\"Country_code2\"], df_languages[\"Country_code3\"] = zip(\n",
    "    *df_languages[\"Country/Region\"].map(get_country_codes)\n",
    ")\n",
    "\n",
    "# Tidy the language column\n",
    "df_languages[\"Official_languages\"] = df_languages[\"Official_languages\"].str.lower()\n",
    "df_languages[\"Official_languages\"] = df_languages[\"Official_languages\"].apply(\n",
    "    lambda x: x.replace(\"all have de facto status\", \"\")\n",
    ")\n",
    "df_languages[\"Official_languages\"] = df_languages[\"Official_languages\"].apply(\n",
    "    lambda x: x.replace(\",\", \"\")\n",
    ")\n",
    "df_languages[\"Official_languages\"] = df_languages[\"Official_languages\"].apply(\n",
    "    lambda x: x.replace(\"(\", \"\")\n",
    ")\n",
    "df_languages[\"Official_languages\"] = df_languages[\"Official_languages\"].apply(\n",
    "    lambda x: x.replace(\")\", \"\")\n",
    ")\n",
    "\n",
    "# Manually add missing languages\n",
    "df_languages.loc[df_languages[\"Country_code2\"] == \"LT\", \"Official_languages\"] = (\n",
    "    \"samogitian \"\n",
    "    + df_languages.loc[df_languages[\"Country_code2\"] == \"LT\", \"Official_languages\"]\n",
    ")\n",
    "df_languages.loc[df_languages[\"Country_code2\"] == \"FR\", \"Official_languages\"] = (\n",
    "    \"breton corsican \"\n",
    "    + df_languages.loc[df_languages[\"Country_code2\"] == \"FR\", \"Official_languages\"]\n",
    ")\n",
    "df_languages.loc[df_languages[\"Country_code2\"] == \"SI\", \"Official_languages\"] = (\n",
    "    \"slovenian \" + df_languages.loc[df_languages[\"Country_code2\"] == \"SI\", \"Official_languages\"]\n",
    ")\n",
    "df_languages.loc[df_languages[\"Country_code2\"] == \"EE\", \"Official_languages\"] = (\n",
    "    \"võro \" + df_languages.loc[df_languages[\"Country_code2\"] == \"EE\", \"Official_languages\"]\n",
    ")\n",
    "\n",
    "df_languages.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Language_sung</th>\n",
       "      <th>Year</th>\n",
       "      <th>Country_code2</th>\n",
       "      <th>Country_code3</th>\n",
       "      <th>Contains_English</th>\n",
       "      <th>Contains_NonEnglish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>croatia</td>\n",
       "      <td>Danijela</td>\n",
       "      <td>[croatian]</td>\n",
       "      <td>1998</td>\n",
       "      <td>HR</td>\n",
       "      <td>HRV</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>greece</td>\n",
       "      <td>Thalassa</td>\n",
       "      <td>[greek]</td>\n",
       "      <td>1998</td>\n",
       "      <td>GR</td>\n",
       "      <td>GRC</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>france</td>\n",
       "      <td>Marie Line</td>\n",
       "      <td>[french]</td>\n",
       "      <td>1998</td>\n",
       "      <td>FR</td>\n",
       "      <td>FRA</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>spain</td>\n",
       "      <td>Mikel Herzog</td>\n",
       "      <td>[spanish]</td>\n",
       "      <td>1998</td>\n",
       "      <td>ES</td>\n",
       "      <td>ESP</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>switzerland</td>\n",
       "      <td>Gunvor</td>\n",
       "      <td>[german]</td>\n",
       "      <td>1998</td>\n",
       "      <td>CH</td>\n",
       "      <td>CHE</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country        Artist Language_sung  Year Country_code2  \\\n",
       "772      croatia      Danijela    [croatian]  1998            HR   \n",
       "773       greece      Thalassa       [greek]  1998            GR   \n",
       "774       france    Marie Line      [french]  1998            FR   \n",
       "775        spain  Mikel Herzog     [spanish]  1998            ES   \n",
       "776  switzerland        Gunvor      [german]  1998            CH   \n",
       "\n",
       "    Country_code3  Contains_English  Contains_NonEnglish  \n",
       "772           HRV             False                 True  \n",
       "773           GRC             False                 True  \n",
       "774           FRA             False                 True  \n",
       "775           ESP             False                 True  \n",
       "776           CHE             False                 True  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print any countries in songs['Country'] that are not in df_languages['Country/Region']\n",
    "if len(set(songs['Country_code2']) - set(df_languages['Country_code2'])) > 0: \n",
    "    countries = list(set(songs['Country_code2']) - set(df_languages['Country_code2']))\n",
    "    raise KeyError(\"Country name \" + ', '.join(countries) + \" was in songs, but not in df_languages.\")\n",
    "\n",
    "# merge df_languages and language on Country and Country/Region\n",
    "songs = pd.merge(songs, df_languages[['Country_code2', 'Official_languages']], left_on='Country_code2', right_on='Country_code2', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Language_sung</th>\n",
       "      <th>Year</th>\n",
       "      <th>Country_code2</th>\n",
       "      <th>Country_code3</th>\n",
       "      <th>Contains_English</th>\n",
       "      <th>Contains_NonEnglish</th>\n",
       "      <th>Official_languages</th>\n",
       "      <th>Contains_Multiple_Languages</th>\n",
       "      <th>Number_of_Languages</th>\n",
       "      <th>Contains_Own_Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>germany</td>\n",
       "      <td>Sürpriz</td>\n",
       "      <td>[german, turkish, english, hebrew]</td>\n",
       "      <td>1999</td>\n",
       "      <td>DE</td>\n",
       "      <td>DEU</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>german</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>lithuania</td>\n",
       "      <td>Skamp</td>\n",
       "      <td>[english, lithuanian, german, french]</td>\n",
       "      <td>2001</td>\n",
       "      <td>LT</td>\n",
       "      <td>LTU</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>samogitian lithuanian</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>israel</td>\n",
       "      <td>Lior Narkis</td>\n",
       "      <td>[hebrew, english, greek, french, spanish]</td>\n",
       "      <td>2003</td>\n",
       "      <td>IL</td>\n",
       "      <td>ISR</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>hebrew</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>ukraine</td>\n",
       "      <td>GreenJolly</td>\n",
       "      <td>[ukrainian, english, 6 other]</td>\n",
       "      <td>2005</td>\n",
       "      <td>UA</td>\n",
       "      <td>UKR</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>poland</td>\n",
       "      <td>Ich Troje (2) feat. Real McCoy</td>\n",
       "      <td>[english, polish, german, russian, spanish]</td>\n",
       "      <td>2006</td>\n",
       "      <td>PL</td>\n",
       "      <td>POL</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>polish</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>portugal</td>\n",
       "      <td>Sabrina</td>\n",
       "      <td>[portuguese, english, french, spanish]</td>\n",
       "      <td>2007</td>\n",
       "      <td>PT</td>\n",
       "      <td>PRT</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>ukraine</td>\n",
       "      <td>Verka Serduchka</td>\n",
       "      <td>[german, english, ukrainian, russian]</td>\n",
       "      <td>2007</td>\n",
       "      <td>UA</td>\n",
       "      <td>UKR</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>romania</td>\n",
       "      <td>Todomondo</td>\n",
       "      <td>[english, italian, spanish, russian, french, r...</td>\n",
       "      <td>2007</td>\n",
       "      <td>RO</td>\n",
       "      <td>ROU</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>romanian</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>ireland</td>\n",
       "      <td>Dustin the Turkey</td>\n",
       "      <td>[english, french, german, italian, spanish]</td>\n",
       "      <td>2008</td>\n",
       "      <td>IE</td>\n",
       "      <td>IRL</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>irish english</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>bulgaria</td>\n",
       "      <td>Sofi Marinova</td>\n",
       "      <td>[bulgarian, 10 other]</td>\n",
       "      <td>2012</td>\n",
       "      <td>BG</td>\n",
       "      <td>BGR</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>bulgarian</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>italy</td>\n",
       "      <td>Francesco Gabbani</td>\n",
       "      <td>[italian, english, sanskrit, ancient greek]</td>\n",
       "      <td>2017</td>\n",
       "      <td>IT</td>\n",
       "      <td>ITA</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>italian</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>denmark</td>\n",
       "      <td>Leonora</td>\n",
       "      <td>[english, french, german, danish]</td>\n",
       "      <td>2019</td>\n",
       "      <td>DK</td>\n",
       "      <td>DNK</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>danish</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>israel</td>\n",
       "      <td>Eden Alene</td>\n",
       "      <td>[english, amharic, hebrew, arabic]</td>\n",
       "      <td>2020</td>\n",
       "      <td>IL</td>\n",
       "      <td>ISR</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>hebrew</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country                          Artist  \\\n",
       "45     germany                         Sürpriz   \n",
       "79   lithuania                           Skamp   \n",
       "131     israel                     Lior Narkis   \n",
       "214    ukraine                      GreenJolly   \n",
       "231     poland  Ich Troje (2) feat. Real McCoy   \n",
       "273   portugal                         Sabrina   \n",
       "295    ukraine                 Verka Serduchka   \n",
       "297    romania                       Todomondo   \n",
       "309    ireland               Dustin the Turkey   \n",
       "491   bulgaria                   Sofi Marinova   \n",
       "702      italy               Francesco Gabbani   \n",
       "774    denmark                         Leonora   \n",
       "812     israel                      Eden Alene   \n",
       "\n",
       "                                         Language_sung  Year Country_code2  \\\n",
       "45                  [german, turkish, english, hebrew]  1999            DE   \n",
       "79               [english, lithuanian, german, french]  2001            LT   \n",
       "131          [hebrew, english, greek, french, spanish]  2003            IL   \n",
       "214                      [ukrainian, english, 6 other]  2005            UA   \n",
       "231        [english, polish, german, russian, spanish]  2006            PL   \n",
       "273             [portuguese, english, french, spanish]  2007            PT   \n",
       "295              [german, english, ukrainian, russian]  2007            UA   \n",
       "297  [english, italian, spanish, russian, french, r...  2007            RO   \n",
       "309        [english, french, german, italian, spanish]  2008            IE   \n",
       "491                              [bulgarian, 10 other]  2012            BG   \n",
       "702        [italian, english, sanskrit, ancient greek]  2017            IT   \n",
       "774                  [english, french, german, danish]  2019            DK   \n",
       "812                 [english, amharic, hebrew, arabic]  2020            IL   \n",
       "\n",
       "    Country_code3  Contains_English  Contains_NonEnglish  \\\n",
       "45            DEU              True                 True   \n",
       "79            LTU              True                 True   \n",
       "131           ISR              True                 True   \n",
       "214           UKR              True                 True   \n",
       "231           POL              True                 True   \n",
       "273           PRT              True                 True   \n",
       "295           UKR              True                 True   \n",
       "297           ROU              True                 True   \n",
       "309           IRL              True                 True   \n",
       "491           BGR             False                 True   \n",
       "702           ITA              True                 True   \n",
       "774           DNK              True                 True   \n",
       "812           ISR              True                 True   \n",
       "\n",
       "        Official_languages  Contains_Multiple_Languages  Number_of_Languages  \\\n",
       "45                  german                         True                    4   \n",
       "79   samogitian lithuanian                         True                    4   \n",
       "131                 hebrew                         True                    5   \n",
       "214              ukrainian                         True                    8   \n",
       "231                 polish                         True                    5   \n",
       "273             portuguese                         True                    4   \n",
       "295              ukrainian                         True                    4   \n",
       "297               romanian                         True                    6   \n",
       "309          irish english                         True                    5   \n",
       "491              bulgarian                         True                   11   \n",
       "702                italian                         True                    4   \n",
       "774                 danish                         True                    4   \n",
       "812                 hebrew                         True                    4   \n",
       "\n",
       "     Contains_Own_Language  \n",
       "45                    True  \n",
       "79                    True  \n",
       "131                   True  \n",
       "214                   True  \n",
       "231                   True  \n",
       "273                   True  \n",
       "295                   True  \n",
       "297                   True  \n",
       "309                   True  \n",
       "491                   True  \n",
       "702                   True  \n",
       "774                   True  \n",
       "812                   True  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tidy the languages column\n",
    "songs['Official_languages'] = songs['Official_languages'].fillna(' ')\n",
    "\n",
    "# Add more columns\n",
    "def get_n_languages(langs):\n",
    "    \"\"\"Get the number of languages in a list of languages\"\"\"\n",
    "    if '6 other' in langs:   # [\"english\", \"6 other\"] -> 7\n",
    "        return len(langs) + 5\n",
    "    elif '10 other' in langs:\n",
    "        return len(langs) + 9\n",
    "    else:\n",
    "        return len(langs)\n",
    "songs['Contains_Multiple_Languages'] = songs['Language_sung'].apply(lambda x: len(x) > 1)\n",
    "songs['Number_of_Languages'] = songs['Language_sung'].apply(get_n_languages)\n",
    "songs['Contains_Own_Language'] = songs.apply(lambda df: len(set(df['Language_sung']).intersection(df['Official_languages'].split())) > 0, axis=1)\n",
    "\n",
    "songs[songs['Number_of_Languages'] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>from_country</th>\n",
       "      <th>to_country</th>\n",
       "      <th>points</th>\n",
       "      <th>from_code2</th>\n",
       "      <th>from_code3</th>\n",
       "      <th>to_code2</th>\n",
       "      <th>to_code3</th>\n",
       "      <th>total_points</th>\n",
       "      <th>rank</th>\n",
       "      <th>...</th>\n",
       "      <th>Year</th>\n",
       "      <th>Country_code2_y</th>\n",
       "      <th>Country_code3</th>\n",
       "      <th>Contains_English</th>\n",
       "      <th>Contains_NonEnglish</th>\n",
       "      <th>Official_languages</th>\n",
       "      <th>Contains_Multiple_Languages</th>\n",
       "      <th>Number_of_Languages</th>\n",
       "      <th>Contains_Own_Language</th>\n",
       "      <th>Contains_Voting_Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>belgium</td>\n",
       "      <td>croatia</td>\n",
       "      <td>5</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>HR</td>\n",
       "      <td>HRV</td>\n",
       "      <td>131</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1998</td>\n",
       "      <td>HR</td>\n",
       "      <td>HRV</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>croatian</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>belgium</td>\n",
       "      <td>cyprus</td>\n",
       "      <td>2</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>CY</td>\n",
       "      <td>CYP</td>\n",
       "      <td>37</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1998</td>\n",
       "      <td>CY</td>\n",
       "      <td>CYP</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>greek turkish</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>belgium</td>\n",
       "      <td>estonia</td>\n",
       "      <td>0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>EE</td>\n",
       "      <td>EST</td>\n",
       "      <td>36</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1998</td>\n",
       "      <td>EE</td>\n",
       "      <td>EST</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>võro estonian</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>belgium</td>\n",
       "      <td>north macedonia</td>\n",
       "      <td>0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>MK</td>\n",
       "      <td>MKD</td>\n",
       "      <td>16</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1998</td>\n",
       "      <td>MK</td>\n",
       "      <td>MKD</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>macedonian albanian</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>belgium</td>\n",
       "      <td>finland</td>\n",
       "      <td>0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>FI</td>\n",
       "      <td>FIN</td>\n",
       "      <td>22</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1998</td>\n",
       "      <td>FI</td>\n",
       "      <td>FIN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>finnish swedish</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year from_country       to_country  points from_code2 from_code3 to_code2  \\\n",
       "0  1998      belgium          croatia       5         BE        BEL       HR   \n",
       "1  1998      belgium           cyprus       2         BE        BEL       CY   \n",
       "2  1998      belgium          estonia       0         BE        BEL       EE   \n",
       "3  1998      belgium  north macedonia       0         BE        BEL       MK   \n",
       "4  1998      belgium          finland       0         BE        BEL       FI   \n",
       "\n",
       "  to_code3  total_points  rank  ...  Year Country_code2_y Country_code3  \\\n",
       "0      HRV           131   5.0  ...  1998              HR           HRV   \n",
       "1      CYP            37  11.0  ...  1998              CY           CYP   \n",
       "2      EST            36  12.0  ...  1998              EE           EST   \n",
       "3      MKD            16  19.0  ...  1998              MK           MKD   \n",
       "4      FIN            22  15.0  ...  1998              FI           FIN   \n",
       "\n",
       "  Contains_English Contains_NonEnglish   Official_languages  \\\n",
       "0            False                True             croatian   \n",
       "1            False                True        greek turkish   \n",
       "2            False                True        võro estonian   \n",
       "3            False                True  macedonian albanian   \n",
       "4            False                True      finnish swedish   \n",
       "\n",
       "  Contains_Multiple_Languages Number_of_Languages  Contains_Own_Language  \\\n",
       "0                       False                   1                   True   \n",
       "1                       False                   1                   True   \n",
       "2                       False                   1                   True   \n",
       "3                       False                   1                   True   \n",
       "4                       False                   1                   True   \n",
       "\n",
       "   Contains_Voting_Language  \n",
       "0                     False  \n",
       "1                     False  \n",
       "2                     False  \n",
       "3                     False  \n",
       "4                     False  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine whether the song is performed in the language of the voting country\n",
    "df_voting_language = df_languages.copy()\n",
    "df_voting_language['Voting_Languages'] = df_voting_language['Official_languages']\n",
    "\n",
    "votes = pd.merge(votes, df_voting_language[['Country_code2', 'Voting_Languages']], \n",
    "                 left_on='from_code2', right_on='Country_code2', how='left')\n",
    "\n",
    "# Combine votes and language\n",
    "df_VL = pd.merge(votes, songs, left_on=['to_code2', 'year'], right_on=['Country_code2', 'Year'], how='left')\n",
    "df_VL['Contains_Voting_Language'] = df_VL.apply(lambda df: len(set(df['Language_sung']).intersection(df['Voting_Languages'].split())) > 0, axis=1)\n",
    "\n",
    "df_VL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21310, 19)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if Country and to_country are identical\n",
    "if not all([all(df_VL['Country'] == df_VL['to_country']),\n",
    "            all(df_VL['Country_code2_x'] == df_VL['from_code2']),\n",
    "            all(df_VL['Country_code2_y'] == df_VL['to_code2']),\n",
    "            all(df_VL['Year'] == df_VL['year'])]):\n",
    "    raise ValueError(\"Mismatch in the merge - check this out!\")\n",
    "\n",
    "df_VL = df_VL[[\n",
    "    'year', 'Artist',\n",
    "    'from_country',\t'to_country', 'points', 'total_points', \n",
    "    'rank',\t'from_code2', 'from_code3', 'to_code2', 'to_code3',\n",
    "    'Official_languages', 'Language_sung',\n",
    "    'Contains_English', 'Contains_NonEnglish', 'Contains_Multiple_Languages',\n",
    "    'Number_of_Languages', 'Contains_Own_Language', 'Contains_Voting_Language']]\n",
    "\n",
    "df_VL.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performer gender\n",
    "\n",
    "We determine the artists gender by scraping the wikipedia page for the performing artist. Artists are classed as either male, female or group. \n",
    "\n",
    "Note that this classification is currently binary. We are aware that some artists do not perform as male or female (e.g. Conchita Wurst) therefore this is not a completely accurate representation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def get_property(session, concept_id, property_id):\n",
    "    \"\"\"Async reimplementation of wikipeople.get_property\n",
    "    https://github.com/samvanstroud/wikipeople/blob/master/wikipeople/wikipeople.py\n",
    "    \n",
    "    session is an aiohttp ClientSession.\n",
    "    concept_id can be obtained using the get_concept_id function\n",
    "    property_id is hardcoded, I don't know where to get these from, but whatever.\n",
    "    \n",
    "    Returns None if any of this can't be found for whatever reason.\n",
    "    \n",
    "    e.g. \"Q219655\" is the concept_id for Carey Mulligan; \"P21\" is the property_id for gender. So we have that\n",
    "        get_property(session, \"Q219655\", \"P21\") -> \"female\"\n",
    "    \"\"\"\n",
    "    url = 'https://www.wikidata.org/w/api.php'\n",
    "    params = {'action': 'wbgetclaims',\n",
    "              'entity': concept_id,\n",
    "              'property': property_id,\n",
    "              'language': 'en',\n",
    "              'format': 'json'}\n",
    "    async with session.get(url, params=params) as resp:\n",
    "        try:\n",
    "            res = await resp.json()\n",
    "        except Exception as e:\n",
    "            print(resp)\n",
    "            raise e\n",
    "\n",
    "    if property_id not in res['claims']:\n",
    "        return None\n",
    "    # This gives yet another 'id', and we then need to perform yet another HTTP\n",
    "    # request to find the actual *label* that this corresponds to.\n",
    "    else:\n",
    "        id = None\n",
    "        for prop in res['claims'][property_id]:\n",
    "            try:\n",
    "                id = prop['mainsnak']['datavalue']['value']['id']\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if id is None:\n",
    "            return None\n",
    "        else:\n",
    "            new_params =  {'action': 'wbgetentities',\n",
    "                           'ids': id,\n",
    "                           'languages': 'en',\n",
    "                           'format': 'json',\n",
    "                           'props': 'labels'}\n",
    "            async with session.get(url, params=new_params) as resp:\n",
    "                try:\n",
    "                    res = await resp.json()\n",
    "                except Exception as e:\n",
    "                    print(resp)\n",
    "                    raise e\n",
    "            try:\n",
    "                return res['entities'][id]['labels']['en']['value']\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "async def get_concept_id(session, page_name):\n",
    "    \"\"\"\n",
    "    Get the concept_id corresponding to a particular Wikipedia page. For some odd reason, some Wikipedia\n",
    "    pages don't have concept IDs. In such a case, we return None.\n",
    "    \n",
    "    e.g. get_concept_id(session, \"Carey Mulligan\") -> \"Q219655\"\n",
    "    \"\"\"\n",
    "    url = 'https://www.wikidata.org/w/api.php'\n",
    "    params = {'action': 'wbsearchentities',\n",
    "              'search': page_name,\n",
    "              'language': 'en',\n",
    "              'format': 'json'}\n",
    "    music_markers = [\n",
    "        'singer', 'artist', 'musician', 'music',\n",
    "        'band', 'group', 'duo', 'ensemble'\n",
    "    ]\n",
    "\n",
    "    async with session.get(url, params=params) as resp:\n",
    "        # Titles of WP pages that match the search query.\n",
    "        json = await resp.json()\n",
    "\n",
    "    result = json['search']\n",
    "\n",
    "    if len(result) == 0:\n",
    "        # Couldn't find a concept id for the person/group\n",
    "        return None\n",
    "\n",
    "    # By default, choose the first result from the list\n",
    "    target = 0\n",
    "    # But check the other results to see if any of them are musicians (as\n",
    "    # indicated by the markers) and Eurovision contestants\n",
    "    for i, res in enumerate(result):\n",
    "        if 'description' in res['display']:\n",
    "            description = res['display']['description']['value']\n",
    "            if any(markers in description for markers in music_markers):\n",
    "                concept_id = res['id']\n",
    "                contestant_in = await get_property(session, concept_id, 'P1344')\n",
    "                if contestant_in is not None and \"Eurovision\" in contestant_in:\n",
    "                    target = i\n",
    "    # Return the concept ID of the result found\n",
    "    return result[target]['id']\n",
    "\n",
    "async def lookup_gender(session, page_name):\n",
    "    \"\"\"Find gender of a performing act, using the name associated with their\n",
    "    Wikipedia page. Returns None if could not be found.\n",
    "    \"\"\"\n",
    "    concept_id = await get_concept_id(session, page_name)\n",
    "    if concept_id is None:\n",
    "        return None\n",
    "\n",
    "    gender = await get_property(session, concept_id, 'P21')\n",
    "    instance = await get_property(session, concept_id, 'P31')\n",
    "    if gender is None and instance is None:\n",
    "        return None\n",
    "    elif gender is None and instance is not None:\n",
    "        group_checks = [\"group\", \"duo\", \"trio\", \"music\", \"band\", \"ensemble\"]\n",
    "        if any(x in instance for x in group_checks):\n",
    "            return \"group\"\n",
    "    else:\n",
    "        return gender\n",
    "\n",
    "async def get_pages(session, name):\n",
    "    \"\"\"Obtain a list of Wikipedia pages obtained by searching for a name.\n",
    "    \"\"\"\n",
    "    url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"opensearch\",\n",
    "        \"namespace\": \"0\",\n",
    "        \"search\": name,\n",
    "        \"limit\": \"10000\",\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    async with session.get(url, params=params) as resp:\n",
    "        # Titles of WP pages that match the search query.\n",
    "        json = await resp.json()\n",
    "    return json[1]\n",
    "\n",
    "async def get_artist_gender(session, name):\n",
    "    gender = None\n",
    "    # Get the WP page for this person/group\n",
    "    pages = await get_pages(session, name)\n",
    "    # If there's one, try to get their gender from the first page\n",
    "    if len(pages) > 0:\n",
    "        gender = await lookup_gender(session, pages[0])\n",
    "    # Finally we use some heuristics to cover some edge cases\n",
    "    if gender is None:\n",
    "        if '&' in name or 'feat.' in name:\n",
    "            return 'group'\n",
    "    \n",
    "    return gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded performer genders from file\n"
     ]
    }
   ],
   "source": [
    "# Check whether the gender data has already been saved. If so, load it in.\n",
    "p = Path(\"../../data/gender_dict.json\")\n",
    "if p.is_file():\n",
    "    with open(p, 'r') as file:\n",
    "        gender_dict = json.load(file)\n",
    "        print('Loaded performer genders from file')\n",
    "        \n",
    "else:\n",
    "    # If not, now that we have all the necessary functionality, we can fetch the data from Wikipedia.\n",
    "    all_performers = df_VL['Artist'].unique().tolist()\n",
    "    n_performers = len(all_performers)\n",
    "    MAX_CONCURRENT = 40   # To stop Wikipedia from complaining about 'too many requests'\n",
    "    USER_AGENT = 'Eurovision study @ The Alan Turing Institute mailto:jyong@turing.ac.uk'\n",
    "\n",
    "    async def get_all_genders():\n",
    "        genders = []\n",
    "        print(f'We need to fetch the genders of {n_performers} performers, in batches of {MAX_CONCURRENT}. Hold tight...')\n",
    "        async with aiohttp.ClientSession(headers={'User-Agent': USER_AGENT}) as session:\n",
    "            start = 0\n",
    "            end = MAX_CONCURRENT\n",
    "            while start < n_performers:\n",
    "                print(f'Getting genders for performers #{start + 1} to #{end}... ', end='')\n",
    "                batch_tasks = asyncio.gather(*[get_artist_gender(session, p) for p in all_performers[start:end]])\n",
    "                batch_genders = await batch_tasks\n",
    "                print(f'Got {len(batch_genders)} results, {len([g for g in batch_genders if g is None])} of which were None.')\n",
    "                genders = genders + batch_genders\n",
    "                start = end\n",
    "                end = min(end + MAX_CONCURRENT, n_performers)\n",
    "                await asyncio.sleep(1.5)   # Put a pause between batches to avoid being timed out\n",
    "        # now pray that I didn't make an off-by-one error somewhere\n",
    "        assert len(genders) == n_performers\n",
    "        print('Finished downloading gender data.')\n",
    "        return dict(zip(all_performers, genders))\n",
    "        \n",
    "    gender_dict = await get_all_genders()\n",
    "    \n",
    "    # Manually assign missing entries (the Nones).\n",
    "    male = ['Michael Hajiyanni', 'Charlie', 'Tüzmen', 'Mietek Szcześniak', 'Olexandr', 'Max', 'Brinck',\n",
    "            'Sakis Rouvas (2)', 'Gianluca', 'Frans', 'Chingiz', 'Mahmood', 'Serhat (2)', 'Miki', 'Stefan']\n",
    "    female = ['Gunvor', 'Selma', 'Charlotte Nilsson (Perrelli)', 'Karolina', 'Laura', 'Rosa', 'Lou', 'Nicola',\n",
    "            'Karmen', 'Sanda', 'Ortal', 'Gracia', 'Chiara (2)', 'Hanna', 'Chiara (3)', 'Elena', 'Lena (2)',\n",
    "            'Birgit', 'Samra', 'ZAA Sanja Vučić', 'Anja', 'Alma', 'Netta', 'Michela', 'Efendi', 'Victoria',\n",
    "            'Destiny', 'Amanda Georgiadi Tenfjord', 'MARO']\n",
    "    group = ['Eden', 'Voice', 'Taxi', 'One', 'Prime Minister', 'Fame', 'Regina (band)', 'ESDM',\n",
    "            'Tolmachevy Sisters', 'Minus One', 'AWS']\n",
    "    for p in male:\n",
    "        gender_dict[p] = \"male\"\n",
    "    for p in female:\n",
    "        gender_dict[p] = \"female\"\n",
    "    for p in group:\n",
    "        gender_dict[p] = \"group\"\n",
    "\n",
    "    # Wikipedia needs to learn that 'trans woman' is 'female'.\n",
    "    for k, v in gender_dict.items():\n",
    "        if v == 'trans woman':\n",
    "            gender_dict[k] = 'female'\n",
    "            \n",
    "    # Save it to a file\n",
    "    with open('../../data/gender_dict.json', 'w') as file:\n",
    "        json.dump(gender_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Artist</th>\n",
       "      <th>from_country</th>\n",
       "      <th>to_country</th>\n",
       "      <th>points</th>\n",
       "      <th>total_points</th>\n",
       "      <th>rank</th>\n",
       "      <th>from_code2</th>\n",
       "      <th>from_code3</th>\n",
       "      <th>to_code2</th>\n",
       "      <th>to_code3</th>\n",
       "      <th>Official_languages</th>\n",
       "      <th>Language_sung</th>\n",
       "      <th>Contains_English</th>\n",
       "      <th>Contains_NonEnglish</th>\n",
       "      <th>Contains_Multiple_Languages</th>\n",
       "      <th>Number_of_Languages</th>\n",
       "      <th>Contains_Own_Language</th>\n",
       "      <th>Contains_Voting_Language</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>Danijela</td>\n",
       "      <td>belgium</td>\n",
       "      <td>croatia</td>\n",
       "      <td>5</td>\n",
       "      <td>131</td>\n",
       "      <td>5.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>HR</td>\n",
       "      <td>HRV</td>\n",
       "      <td>croatian</td>\n",
       "      <td>[croatian]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>Michael Hajiyanni</td>\n",
       "      <td>belgium</td>\n",
       "      <td>cyprus</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>11.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>CY</td>\n",
       "      <td>CYP</td>\n",
       "      <td>greek turkish</td>\n",
       "      <td>[greek]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>Koit Toome</td>\n",
       "      <td>belgium</td>\n",
       "      <td>estonia</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>12.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>EE</td>\n",
       "      <td>EST</td>\n",
       "      <td>võro estonian</td>\n",
       "      <td>[estonian]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>Vlado Janevski</td>\n",
       "      <td>belgium</td>\n",
       "      <td>north macedonia</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>19.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>MK</td>\n",
       "      <td>MKD</td>\n",
       "      <td>macedonian albanian</td>\n",
       "      <td>[macedonian]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>Edea</td>\n",
       "      <td>belgium</td>\n",
       "      <td>finland</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>15.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>FI</td>\n",
       "      <td>FIN</td>\n",
       "      <td>finnish swedish</td>\n",
       "      <td>[finnish]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year             Artist from_country       to_country  points  \\\n",
       "0  1998           Danijela      belgium          croatia       5   \n",
       "1  1998  Michael Hajiyanni      belgium           cyprus       2   \n",
       "2  1998         Koit Toome      belgium          estonia       0   \n",
       "3  1998     Vlado Janevski      belgium  north macedonia       0   \n",
       "4  1998               Edea      belgium          finland       0   \n",
       "\n",
       "   total_points  rank from_code2 from_code3 to_code2 to_code3  \\\n",
       "0           131   5.0         BE        BEL       HR      HRV   \n",
       "1            37  11.0         BE        BEL       CY      CYP   \n",
       "2            36  12.0         BE        BEL       EE      EST   \n",
       "3            16  19.0         BE        BEL       MK      MKD   \n",
       "4            22  15.0         BE        BEL       FI      FIN   \n",
       "\n",
       "    Official_languages Language_sung  Contains_English  Contains_NonEnglish  \\\n",
       "0             croatian    [croatian]             False                 True   \n",
       "1        greek turkish       [greek]             False                 True   \n",
       "2        võro estonian    [estonian]             False                 True   \n",
       "3  macedonian albanian  [macedonian]             False                 True   \n",
       "4      finnish swedish     [finnish]             False                 True   \n",
       "\n",
       "   Contains_Multiple_Languages  Number_of_Languages  Contains_Own_Language  \\\n",
       "0                        False                    1                   True   \n",
       "1                        False                    1                   True   \n",
       "2                        False                    1                   True   \n",
       "3                        False                    1                   True   \n",
       "4                        False                    1                   True   \n",
       "\n",
       "   Contains_Voting_Language  gender  \n",
       "0                     False  female  \n",
       "1                     False    male  \n",
       "2                     False    male  \n",
       "3                     False    male  \n",
       "4                     False   group  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add gender to the dataframe.\n",
    "df_VLG = df_VL.copy()\n",
    "df_VLG['gender'] = df_VLG['Artist'].map(gender_dict)\n",
    "df_VLG.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All years are consistent!\n"
     ]
    }
   ],
   "source": [
    "check_consistency(df_VLG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Migration\n",
    "\n",
    "- The `migration-flows.csv` data is from [Our World in Data](https://ourworldindata.org/migration) on international migration, under the 'Explore data on where people migrate from and to' section.\n",
    "- Original source is from the UN.\n",
    "- Data shows total number of immigrants in each country split by country of origin in the years 1990-2020, recorded at intervals of every 5 years.\n",
    "- Additional population size data (`pop_sizes.csv`) is taken from the [World Bank](https://data.worldbank.org/indicator/SP.POP.TOTL?end=2021&start=2021&view=map)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emigrated_to</th>\n",
       "      <th>year</th>\n",
       "      <th>emigrated_from</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>1990</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>1995</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2000</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2005</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2010</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emigrated_to  year emigrated_from  count\n",
       "56    Argentina  1990    Afghanistan     20\n",
       "57    Argentina  1995    Afghanistan     20\n",
       "58    Argentina  2000    Afghanistan     20\n",
       "59    Argentina  2005    Afghanistan     16\n",
       "60    Argentina  2010    Afghanistan      9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "migration = pd.read_csv('../../data/migration-flows.csv')\n",
    "\n",
    "# Martin actually writes good pandas code, unlike me\n",
    "\n",
    "migration = (migration\n",
    "    .pipe(pd.melt, id_vars=['Country', 'Year'], var_name='Migration', value_name='Count')  # to long format\n",
    "    .loc[lambda x: x['Migration'].str.contains('Emigrants')]                               # filter for emigrant rows\n",
    "    .pipe(lambda x: x.rename(columns = {col: col.lower() for col in x.columns}))           # lowercase column names                                                         \n",
    "    .assign(migration = lambda x: x.migration.str.replace('Emigrants from ', ''))          # filter for emigrant rows                          \n",
    "    .rename(columns={'migration': 'emigrated_from', 'country': 'emigrated_to'})            # boil down to country name\n",
    "    .query('count >= 0')                                                                   # negative counts are just total emigrants from country\n",
    "    .pipe(lambda x: x.assign(count = x['count'].astype(int)))                              # convert count to int     \n",
    ")\n",
    "migration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yugoslavia'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emigrated_to</th>\n",
       "      <th>year</th>\n",
       "      <th>emigrated_from</th>\n",
       "      <th>count</th>\n",
       "      <th>emigrated_from_code2</th>\n",
       "      <th>emigrated_from_code3</th>\n",
       "      <th>emigrated_to_code2</th>\n",
       "      <th>emigrated_to_code3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>australia</td>\n",
       "      <td>1990</td>\n",
       "      <td>albania</td>\n",
       "      <td>984</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>australia</td>\n",
       "      <td>1995</td>\n",
       "      <td>albania</td>\n",
       "      <td>1315</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>australia</td>\n",
       "      <td>2000</td>\n",
       "      <td>albania</td>\n",
       "      <td>1530</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>australia</td>\n",
       "      <td>2005</td>\n",
       "      <td>albania</td>\n",
       "      <td>2270</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>australia</td>\n",
       "      <td>2010</td>\n",
       "      <td>albania</td>\n",
       "      <td>2880</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emigrated_to  year emigrated_from  count emigrated_from_code2  \\\n",
       "0    australia  1990        albania    984                   AL   \n",
       "1    australia  1995        albania   1315                   AL   \n",
       "2    australia  2000        albania   1530                   AL   \n",
       "3    australia  2005        albania   2270                   AL   \n",
       "4    australia  2010        albania   2880                   AL   \n",
       "\n",
       "  emigrated_from_code3 emigrated_to_code2 emigrated_to_code3  \n",
       "0                  ALB                 AU                AUS  \n",
       "1                  ALB                 AU                AUS  \n",
       "2                  ALB                 AU                AUS  \n",
       "3                  ALB                 AU                AUS  \n",
       "4                  ALB                 AU                AUS  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up country names\n",
    "for ft in ['from', 'to']:\n",
    "    migration[f'emigrated_{ft}'] = migration[f'emigrated_{ft}'].str.lower()\n",
    "    migration.loc[migration[f'emigrated_{ft}'] == 'moldova', f'emigrated_{ft}'] = 'moldova, republic of'\n",
    "    migration.loc[migration[f'emigrated_{ft}'] == 'russia', f'emigrated_{ft}'] = 'russian federation'\n",
    "\n",
    "# Remove countries we don't care about\n",
    "ev_countries = set(df_VLG['from_country'].unique()).union(set(df_VLG['to_country'].unique()))\n",
    "migration = migration[(migration['emigrated_to'].isin(ev_countries)) & (migration['emigrated_from'].isin(ev_countries))]\n",
    "\n",
    "migration_countries = set(migration['emigrated_to'].unique()).union(set(migration['emigrated_from'].unique()))\n",
    "print(ev_countries - migration_countries)  # No data for Yugoslavia.\n",
    "\n",
    "# Add in country codes\n",
    "for ft in ['from', 'to']:\n",
    "    migration[f'emigrated_{ft}_code2'], migration[f'emigrated_{ft}_code3'] = zip(*migration[f'emigrated_{ft}'].map(get_country_codes))\n",
    "    \n",
    "migration = migration.reset_index(drop=True)\n",
    "migration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emigrated_to</th>\n",
       "      <th>year</th>\n",
       "      <th>emigrated_from</th>\n",
       "      <th>count</th>\n",
       "      <th>emigrated_from_code2</th>\n",
       "      <th>emigrated_from_code3</th>\n",
       "      <th>emigrated_to_code2</th>\n",
       "      <th>emigrated_to_code3</th>\n",
       "      <th>code3</th>\n",
       "      <th>population_to</th>\n",
       "      <th>prop_emigrants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>australia</td>\n",
       "      <td>1990</td>\n",
       "      <td>albania</td>\n",
       "      <td>984</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "      <td>AUS</td>\n",
       "      <td>17065128.0</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>australia</td>\n",
       "      <td>1995</td>\n",
       "      <td>albania</td>\n",
       "      <td>1315</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "      <td>AUS</td>\n",
       "      <td>18004882.0</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>australia</td>\n",
       "      <td>2000</td>\n",
       "      <td>albania</td>\n",
       "      <td>1530</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "      <td>AUS</td>\n",
       "      <td>19028802.0</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>australia</td>\n",
       "      <td>2005</td>\n",
       "      <td>albania</td>\n",
       "      <td>2270</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "      <td>AUS</td>\n",
       "      <td>20176844.0</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>australia</td>\n",
       "      <td>2010</td>\n",
       "      <td>albania</td>\n",
       "      <td>2880</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "      <td>AUS</td>\n",
       "      <td>22031750.0</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>australia</td>\n",
       "      <td>2015</td>\n",
       "      <td>albania</td>\n",
       "      <td>3460</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "      <td>AUS</td>\n",
       "      <td>23815995.0</td>\n",
       "      <td>0.000145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>australia</td>\n",
       "      <td>2020</td>\n",
       "      <td>albania</td>\n",
       "      <td>3941</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "      <td>AUS</td>\n",
       "      <td>25655289.0</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>austria</td>\n",
       "      <td>1990</td>\n",
       "      <td>albania</td>\n",
       "      <td>1733</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AT</td>\n",
       "      <td>AUT</td>\n",
       "      <td>AUT</td>\n",
       "      <td>7677850.0</td>\n",
       "      <td>0.000226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>austria</td>\n",
       "      <td>1995</td>\n",
       "      <td>albania</td>\n",
       "      <td>1955</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AT</td>\n",
       "      <td>AUT</td>\n",
       "      <td>AUT</td>\n",
       "      <td>7948278.0</td>\n",
       "      <td>0.000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>austria</td>\n",
       "      <td>2000</td>\n",
       "      <td>albania</td>\n",
       "      <td>2177</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AT</td>\n",
       "      <td>AUT</td>\n",
       "      <td>AUT</td>\n",
       "      <td>8011566.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>austria</td>\n",
       "      <td>2005</td>\n",
       "      <td>albania</td>\n",
       "      <td>2414</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AT</td>\n",
       "      <td>AUT</td>\n",
       "      <td>AUT</td>\n",
       "      <td>8227829.0</td>\n",
       "      <td>0.000293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>austria</td>\n",
       "      <td>2010</td>\n",
       "      <td>albania</td>\n",
       "      <td>2681</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AT</td>\n",
       "      <td>AUT</td>\n",
       "      <td>AUT</td>\n",
       "      <td>8363404.0</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>austria</td>\n",
       "      <td>2015</td>\n",
       "      <td>albania</td>\n",
       "      <td>3230</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AT</td>\n",
       "      <td>AUT</td>\n",
       "      <td>AUT</td>\n",
       "      <td>8642699.0</td>\n",
       "      <td>0.000374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>austria</td>\n",
       "      <td>2020</td>\n",
       "      <td>albania</td>\n",
       "      <td>4398</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AT</td>\n",
       "      <td>AUT</td>\n",
       "      <td>AUT</td>\n",
       "      <td>8916864.0</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>belgium</td>\n",
       "      <td>1990</td>\n",
       "      <td>albania</td>\n",
       "      <td>2157</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>BEL</td>\n",
       "      <td>9967379.0</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>belgium</td>\n",
       "      <td>1995</td>\n",
       "      <td>albania</td>\n",
       "      <td>2143</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>BEL</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>belgium</td>\n",
       "      <td>2000</td>\n",
       "      <td>albania</td>\n",
       "      <td>2067</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>BEL</td>\n",
       "      <td>10251250.0</td>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>belgium</td>\n",
       "      <td>2005</td>\n",
       "      <td>albania</td>\n",
       "      <td>3277</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>BEL</td>\n",
       "      <td>10478617.0</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>belgium</td>\n",
       "      <td>2010</td>\n",
       "      <td>albania</td>\n",
       "      <td>6129</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>BEL</td>\n",
       "      <td>10895586.0</td>\n",
       "      <td>0.000563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>belgium</td>\n",
       "      <td>2015</td>\n",
       "      <td>albania</td>\n",
       "      <td>9380</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>BEL</td>\n",
       "      <td>11274196.0</td>\n",
       "      <td>0.000832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emigrated_to  year emigrated_from  count emigrated_from_code2  \\\n",
       "0     australia  1990        albania    984                   AL   \n",
       "1     australia  1995        albania   1315                   AL   \n",
       "2     australia  2000        albania   1530                   AL   \n",
       "3     australia  2005        albania   2270                   AL   \n",
       "4     australia  2010        albania   2880                   AL   \n",
       "5     australia  2015        albania   3460                   AL   \n",
       "6     australia  2020        albania   3941                   AL   \n",
       "7       austria  1990        albania   1733                   AL   \n",
       "8       austria  1995        albania   1955                   AL   \n",
       "9       austria  2000        albania   2177                   AL   \n",
       "10      austria  2005        albania   2414                   AL   \n",
       "11      austria  2010        albania   2681                   AL   \n",
       "12      austria  2015        albania   3230                   AL   \n",
       "13      austria  2020        albania   4398                   AL   \n",
       "14      belgium  1990        albania   2157                   AL   \n",
       "15      belgium  1995        albania   2143                   AL   \n",
       "16      belgium  2000        albania   2067                   AL   \n",
       "17      belgium  2005        albania   3277                   AL   \n",
       "18      belgium  2010        albania   6129                   AL   \n",
       "19      belgium  2015        albania   9380                   AL   \n",
       "\n",
       "   emigrated_from_code3 emigrated_to_code2 emigrated_to_code3 code3  \\\n",
       "0                   ALB                 AU                AUS   AUS   \n",
       "1                   ALB                 AU                AUS   AUS   \n",
       "2                   ALB                 AU                AUS   AUS   \n",
       "3                   ALB                 AU                AUS   AUS   \n",
       "4                   ALB                 AU                AUS   AUS   \n",
       "5                   ALB                 AU                AUS   AUS   \n",
       "6                   ALB                 AU                AUS   AUS   \n",
       "7                   ALB                 AT                AUT   AUT   \n",
       "8                   ALB                 AT                AUT   AUT   \n",
       "9                   ALB                 AT                AUT   AUT   \n",
       "10                  ALB                 AT                AUT   AUT   \n",
       "11                  ALB                 AT                AUT   AUT   \n",
       "12                  ALB                 AT                AUT   AUT   \n",
       "13                  ALB                 AT                AUT   AUT   \n",
       "14                  ALB                 BE                BEL   BEL   \n",
       "15                  ALB                 BE                BEL   BEL   \n",
       "16                  ALB                 BE                BEL   BEL   \n",
       "17                  ALB                 BE                BEL   BEL   \n",
       "18                  ALB                 BE                BEL   BEL   \n",
       "19                  ALB                 BE                BEL   BEL   \n",
       "\n",
       "    population_to  prop_emigrants  \n",
       "0      17065128.0        0.000058  \n",
       "1      18004882.0        0.000073  \n",
       "2      19028802.0        0.000080  \n",
       "3      20176844.0        0.000113  \n",
       "4      22031750.0        0.000131  \n",
       "5      23815995.0        0.000145  \n",
       "6      25655289.0        0.000154  \n",
       "7       7677850.0        0.000226  \n",
       "8       7948278.0        0.000246  \n",
       "9       8011566.0        0.000272  \n",
       "10      8227829.0        0.000293  \n",
       "11      8363404.0        0.000321  \n",
       "12      8642699.0        0.000374  \n",
       "13      8916864.0        0.000493  \n",
       "14      9967379.0        0.000216  \n",
       "15     10136811.0        0.000211  \n",
       "16     10251250.0        0.000202  \n",
       "17     10478617.0        0.000313  \n",
       "18     10895586.0        0.000563  \n",
       "19     11274196.0        0.000832  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_size = (pd.read_csv('../../data/pop_sizes.csv')\n",
    "           .iloc[:, 3:]\n",
    "           .rename(columns=lambda x: x.lower().replace(' ', '_'))\n",
    "           .pipe(pd.melt, id_vars=['country_code'], var_name='year', value_name='population')\n",
    "           .assign(year=lambda x: x['year'].apply(lambda y: y.split('_')[0]))\n",
    "           .assign(year=lambda x: x['year'].astype(int))\n",
    "           .rename(columns={'country_code': 'code3'})\n",
    "           .dropna()\n",
    "           .assign(population=lambda x: pd.to_numeric(x['population'], errors='coerce'))\n",
    ")\n",
    "pop_size.head()\n",
    "\n",
    "migration_and_pop = (migration.merge(pop_size, left_on=['year', 'emigrated_to_code3'], right_on=['year', 'code3'], how='left')\n",
    "                     .rename(columns={'population': 'population_to'})\n",
    "                    .assign(prop_emigrants=lambda x: x['count'] / x['population_to'])\n",
    "                    #.reindex(columns=['country', 'code', 'code3', 'population', 'year', 'emigrated_from_code', 'count', 'prop_emigrants'])\n",
    "                    )\n",
    "migration_and_pop.head(n=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we don't have migration data for every year, when merging with the main dataset, we take the last migration data point before the competition.\n",
    "So, for example, the 2012 entries will contain migration data from 2010.\n",
    "\n",
    "To do this, we'll first make 5 copies of each row from the `migration_and_pop` dataframe, each with a different year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emigrated_from_code2</th>\n",
       "      <th>emigrated_to_code2</th>\n",
       "      <th>year</th>\n",
       "      <th>count</th>\n",
       "      <th>population_to</th>\n",
       "      <th>prop_emigrants</th>\n",
       "      <th>migration_pop_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>1990</td>\n",
       "      <td>984</td>\n",
       "      <td>17065128.0</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12313</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>1991</td>\n",
       "      <td>984</td>\n",
       "      <td>17065128.0</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24626</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>1992</td>\n",
       "      <td>984</td>\n",
       "      <td>17065128.0</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36939</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>1993</td>\n",
       "      <td>984</td>\n",
       "      <td>17065128.0</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49252</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>1994</td>\n",
       "      <td>984</td>\n",
       "      <td>17065128.0</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>1995</td>\n",
       "      <td>1315</td>\n",
       "      <td>18004882.0</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12314</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>1996</td>\n",
       "      <td>1315</td>\n",
       "      <td>18004882.0</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24627</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>1997</td>\n",
       "      <td>1315</td>\n",
       "      <td>18004882.0</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36940</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>1998</td>\n",
       "      <td>1315</td>\n",
       "      <td>18004882.0</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49253</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>1999</td>\n",
       "      <td>1315</td>\n",
       "      <td>18004882.0</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>2000</td>\n",
       "      <td>1530</td>\n",
       "      <td>19028802.0</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12315</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>2001</td>\n",
       "      <td>1530</td>\n",
       "      <td>19028802.0</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24628</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>2002</td>\n",
       "      <td>1530</td>\n",
       "      <td>19028802.0</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36941</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>2003</td>\n",
       "      <td>1530</td>\n",
       "      <td>19028802.0</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49254</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>2004</td>\n",
       "      <td>1530</td>\n",
       "      <td>19028802.0</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>2005</td>\n",
       "      <td>2270</td>\n",
       "      <td>20176844.0</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12316</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>2006</td>\n",
       "      <td>2270</td>\n",
       "      <td>20176844.0</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24629</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>2007</td>\n",
       "      <td>2270</td>\n",
       "      <td>20176844.0</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36942</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>2008</td>\n",
       "      <td>2270</td>\n",
       "      <td>20176844.0</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49255</th>\n",
       "      <td>AL</td>\n",
       "      <td>AU</td>\n",
       "      <td>2009</td>\n",
       "      <td>2270</td>\n",
       "      <td>20176844.0</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      emigrated_from_code2 emigrated_to_code2  year  count  population_to  \\\n",
       "0                       AL                 AU  1990    984     17065128.0   \n",
       "12313                   AL                 AU  1991    984     17065128.0   \n",
       "24626                   AL                 AU  1992    984     17065128.0   \n",
       "36939                   AL                 AU  1993    984     17065128.0   \n",
       "49252                   AL                 AU  1994    984     17065128.0   \n",
       "1                       AL                 AU  1995   1315     18004882.0   \n",
       "12314                   AL                 AU  1996   1315     18004882.0   \n",
       "24627                   AL                 AU  1997   1315     18004882.0   \n",
       "36940                   AL                 AU  1998   1315     18004882.0   \n",
       "49253                   AL                 AU  1999   1315     18004882.0   \n",
       "2                       AL                 AU  2000   1530     19028802.0   \n",
       "12315                   AL                 AU  2001   1530     19028802.0   \n",
       "24628                   AL                 AU  2002   1530     19028802.0   \n",
       "36941                   AL                 AU  2003   1530     19028802.0   \n",
       "49254                   AL                 AU  2004   1530     19028802.0   \n",
       "3                       AL                 AU  2005   2270     20176844.0   \n",
       "12316                   AL                 AU  2006   2270     20176844.0   \n",
       "24629                   AL                 AU  2007   2270     20176844.0   \n",
       "36942                   AL                 AU  2008   2270     20176844.0   \n",
       "49255                   AL                 AU  2009   2270     20176844.0   \n",
       "\n",
       "       prop_emigrants  migration_pop_year  \n",
       "0            0.000058                1990  \n",
       "12313        0.000058                1990  \n",
       "24626        0.000058                1990  \n",
       "36939        0.000058                1990  \n",
       "49252        0.000058                1990  \n",
       "1            0.000073                1995  \n",
       "12314        0.000073                1995  \n",
       "24627        0.000073                1995  \n",
       "36940        0.000073                1995  \n",
       "49253        0.000073                1995  \n",
       "2            0.000080                2000  \n",
       "12315        0.000080                2000  \n",
       "24628        0.000080                2000  \n",
       "36941        0.000080                2000  \n",
       "49254        0.000080                2000  \n",
       "3            0.000113                2005  \n",
       "12316        0.000113                2005  \n",
       "24629        0.000113                2005  \n",
       "36942        0.000113                2005  \n",
       "49255        0.000113                2005  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "migration_and_pop['migration_pop_year'] = migration_and_pop['year']\n",
    "\n",
    "total_migration_and_pop = migration_and_pop.copy()\n",
    "for i in range(1, 5):\n",
    "    next_migration_and_pop = migration_and_pop.copy()\n",
    "    next_migration_and_pop['year'] = next_migration_and_pop['year'] + i\n",
    "    total_migration_and_pop = pd.concat([total_migration_and_pop, next_migration_and_pop], ignore_index=True)\n",
    "    \n",
    "total_migration_and_pop = total_migration_and_pop.sort_values(by=[\"emigrated_from\", \"emigrated_to\", \"year\"])\n",
    "\n",
    "total_migration_and_pop = total_migration_and_pop[['emigrated_from_code2', 'emigrated_to_code2', 'year', 'count', 'population_to', 'prop_emigrants', 'migration_pop_year']]\n",
    "\n",
    "total_migration_and_pop.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Artist</th>\n",
       "      <th>from_country</th>\n",
       "      <th>to_country</th>\n",
       "      <th>points</th>\n",
       "      <th>total_points</th>\n",
       "      <th>rank</th>\n",
       "      <th>from_code2</th>\n",
       "      <th>from_code3</th>\n",
       "      <th>to_code2</th>\n",
       "      <th>...</th>\n",
       "      <th>Contains_Own_Language</th>\n",
       "      <th>Contains_Voting_Language</th>\n",
       "      <th>gender</th>\n",
       "      <th>migration_v2p</th>\n",
       "      <th>population_p</th>\n",
       "      <th>prop_emigrants_v2p</th>\n",
       "      <th>migration_p2v</th>\n",
       "      <th>population_v</th>\n",
       "      <th>prop_emigrants_p2v</th>\n",
       "      <th>migration_pop_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>Danijela</td>\n",
       "      <td>belgium</td>\n",
       "      <td>croatia</td>\n",
       "      <td>5</td>\n",
       "      <td>131</td>\n",
       "      <td>5.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>HR</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>female</td>\n",
       "      <td>205.0</td>\n",
       "      <td>4620030.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>72.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>Michael Hajiyanni</td>\n",
       "      <td>belgium</td>\n",
       "      <td>cyprus</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>11.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>CY</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>male</td>\n",
       "      <td>92.0</td>\n",
       "      <td>862418.0</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>Koit Toome</td>\n",
       "      <td>belgium</td>\n",
       "      <td>estonia</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>12.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>EE</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1436634.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>Vlado Janevski</td>\n",
       "      <td>belgium</td>\n",
       "      <td>north macedonia</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>19.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>MK</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>Edea</td>\n",
       "      <td>belgium</td>\n",
       "      <td>finland</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>15.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>FI</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>group</td>\n",
       "      <td>144.0</td>\n",
       "      <td>5107790.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1998</td>\n",
       "      <td>Marie Line</td>\n",
       "      <td>belgium</td>\n",
       "      <td>france</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>FR</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>female</td>\n",
       "      <td>132113.0</td>\n",
       "      <td>59543659.0</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>123438.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.012177</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1998</td>\n",
       "      <td>Guildo Horn feat. Die Orthopädischen Strümpfe</td>\n",
       "      <td>belgium</td>\n",
       "      <td>germany</td>\n",
       "      <td>7</td>\n",
       "      <td>86</td>\n",
       "      <td>7.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>DE</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>group</td>\n",
       "      <td>22307.0</td>\n",
       "      <td>81678051.0</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>65226.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998</td>\n",
       "      <td>Thalassa</td>\n",
       "      <td>belgium</td>\n",
       "      <td>greece</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>20.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>GR</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>group</td>\n",
       "      <td>4916.0</td>\n",
       "      <td>10562153.0</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>18488.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1998</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>belgium</td>\n",
       "      <td>hungary</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>HU</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>male</td>\n",
       "      <td>601.0</td>\n",
       "      <td>10328965.0</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1998</td>\n",
       "      <td>Dawn Martin</td>\n",
       "      <td>belgium</td>\n",
       "      <td>ireland</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>IE</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>female</td>\n",
       "      <td>507.0</td>\n",
       "      <td>3608841.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                         Artist from_country  \\\n",
       "0  1998                                       Danijela      belgium   \n",
       "1  1998                              Michael Hajiyanni      belgium   \n",
       "2  1998                                     Koit Toome      belgium   \n",
       "3  1998                                 Vlado Janevski      belgium   \n",
       "4  1998                                           Edea      belgium   \n",
       "5  1998                                     Marie Line      belgium   \n",
       "6  1998  Guildo Horn feat. Die Orthopädischen Strümpfe      belgium   \n",
       "7  1998                                       Thalassa      belgium   \n",
       "8  1998                                        Charlie      belgium   \n",
       "9  1998                                    Dawn Martin      belgium   \n",
       "\n",
       "        to_country  points  total_points  rank from_code2 from_code3 to_code2  \\\n",
       "0          croatia       5           131   5.0         BE        BEL       HR   \n",
       "1           cyprus       2            37  11.0         BE        BEL       CY   \n",
       "2          estonia       0            36  12.0         BE        BEL       EE   \n",
       "3  north macedonia       0            16  19.0         BE        BEL       MK   \n",
       "4          finland       0            22  15.0         BE        BEL       FI   \n",
       "5           france       0             3  24.0         BE        BEL       FR   \n",
       "6          germany       7            86   7.0         BE        BEL       DE   \n",
       "7           greece       0            12  20.0         BE        BEL       GR   \n",
       "8          hungary       0             4  23.0         BE        BEL       HU   \n",
       "9          ireland       0            64   9.0         BE        BEL       IE   \n",
       "\n",
       "   ... Contains_Own_Language Contains_Voting_Language  gender  migration_v2p  \\\n",
       "0  ...                  True                    False  female          205.0   \n",
       "1  ...                  True                    False    male           92.0   \n",
       "2  ...                  True                    False    male            0.0   \n",
       "3  ...                  True                    False    male            NaN   \n",
       "4  ...                  True                    False   group          144.0   \n",
       "5  ...                  True                     True  female       132113.0   \n",
       "6  ...                  True                     True   group        22307.0   \n",
       "7  ...                  True                    False   group         4916.0   \n",
       "8  ...                  True                    False    male          601.0   \n",
       "9  ...                  True                    False  female          507.0   \n",
       "\n",
       "   population_p  prop_emigrants_v2p  migration_p2v  population_v  \\\n",
       "0     4620030.0            0.000044           72.0    10136811.0   \n",
       "1      862418.0            0.000107           77.0    10136811.0   \n",
       "2     1436634.0            0.000000           57.0    10136811.0   \n",
       "3           NaN                 NaN          120.0    10136811.0   \n",
       "4     5107790.0            0.000028         1541.0    10136811.0   \n",
       "5    59543659.0            0.002219       123438.0    10136811.0   \n",
       "6    81678051.0            0.000273        65226.0    10136811.0   \n",
       "7    10562153.0            0.000465        18488.0    10136811.0   \n",
       "8    10328965.0            0.000058         1593.0    10136811.0   \n",
       "9     3608841.0            0.000140         2195.0    10136811.0   \n",
       "\n",
       "   prop_emigrants_p2v migration_pop_year  \n",
       "0            0.000007             1995.0  \n",
       "1            0.000008             1995.0  \n",
       "2            0.000006             1995.0  \n",
       "3            0.000012             1995.0  \n",
       "4            0.000152             1995.0  \n",
       "5            0.012177             1995.0  \n",
       "6            0.006435             1995.0  \n",
       "7            0.001824             1995.0  \n",
       "8            0.000157             1995.0  \n",
       "9            0.000217             1995.0  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can join with the main dataframe.\n",
    "\n",
    "# migration_v2p      -> number of migrants from voting country to performing country\n",
    "# population_p       -> population of performing country\n",
    "# prop_emigrants_v2p -> proportion of migrants from voting country in population of performing country\n",
    "df_VLGM = df_VLG.merge(total_migration_and_pop, how='left', left_on=['from_code2', 'to_code2', 'year'], right_on=['emigrated_from_code2', 'emigrated_to_code2', 'year'])\n",
    "df_VLGM = (df_VLGM\n",
    "           .drop(columns=['emigrated_from_code2', 'emigrated_to_code2', 'migration_pop_year'])\n",
    "           .rename(columns={'count': 'migration_v2p', 'population_to': 'population_p', 'prop_emigrants': 'prop_emigrants_v2p'})\n",
    ")\n",
    "\n",
    "# migration_p2v      -> number of migrants from performing country to voting country\n",
    "# population_p       -> population of voting country\n",
    "# prop_emigrants_v2p -> proportion of migrants from performing country in population of voting country\n",
    "# migration_pop_year -> year from which the migration and population data is taken\n",
    "df_VLGM = df_VLGM.merge(total_migration_and_pop, how='left', left_on=['from_code2', 'to_code2', 'year'], right_on=['emigrated_to_code2', 'emigrated_from_code2', 'year'])\n",
    "df_VLGM = (df_VLGM\n",
    "           .drop(columns=['emigrated_from_code2', 'emigrated_to_code2'])\n",
    "           .rename(columns={'count': 'migration_p2v', 'population_to': 'population_v', 'prop_emigrants': 'prop_emigrants_p2v'})\n",
    ")\n",
    "df_VLGM['migration_pop_year'] = df_VLGM['migration_pop_year'].astype(int, errors='ignore')   # ignore NaN's.\n",
    "\n",
    "df_VLGM.head(n=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comps without win\n",
    "\n",
    "Copy the winners from wikipedia. Note that Luxembourg withdrew from the contest in 1994, so is not included in our data - hence why it does not merge, we will remove this from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\n",
    "    f\"https://en.wikipedia.org/wiki/List_of_Eurovision_Song_Contest_winners\"\n",
    ")\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "table = soup.find_all(\"table\", {\"class\": \"wikitable\"})[0]\n",
    "winners = pd.DataFrame(pd.read_html(str(table))[0])\n",
    "\n",
    "winners = winners.loc[winners['Year'] != 2020, ['Year', 'Country']]\n",
    "winners = list(winners.to_records(index=False))\n",
    "\n",
    "winners = [(year, 'Russian federation' if Country == 'Russia' else Country) for year, Country in winners]\n",
    "winners = [(year, get_country_codes(Country.lower())[0]) for year, Country in winners if Country != 'Luxembourg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CH': [1956, 1988], 'NL': [1957, 1959, 1969, 1975, 2019], 'FR': [1958, 1960, 1962, 1969, 1977], 'DK': [1963, 2000, 2013], 'IT': [1964, 1990, 2021], 'AT': [1966, 2014], 'GB': [1967, 1969, 1976, 1981, 1997], 'ES': [1968, 1969], 'IE': [1970, 1980, 1987, 1992, 1993, 1994, 1996], 'MC': [1971], 'SE': [1974, 1984, 1991, 1999, 2012, 2015], 'IL': [1978, 1979, 1998, 2018], 'DE': [1982, 2010], 'NO': [1985, 1995, 2009], 'BE': [1986], 'YU': [1989], 'EE': [2001], 'LV': [2002], 'TR': [2003], 'UA': [2004, 2016, 2022], 'GR': [2005], 'FI': [2006], 'RS': [2007], 'RU': [2008], 'AZ': [2011], 'PT': [2017]}\n"
     ]
    }
   ],
   "source": [
    "# Construct a dictionary mapping each country to the years they won in.\n",
    "all_wins = {}\n",
    "\n",
    "# for each row in winners, get the country code and year\n",
    "for y, code in winners:\n",
    "    if code in all_wins:\n",
    "        all_wins[code].append(y)\n",
    "    else:\n",
    "        all_wins[code] = [y]\n",
    "\n",
    "print(all_wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VLGMC = df_VLGM.copy()\n",
    "\n",
    "def comps_without_win(code, year):\n",
    "      # Find last win. Use 1955 (year before ESC started) if there isn't one.\n",
    "      if code not in all_wins:\n",
    "        last_win = 1955\n",
    "      else:\n",
    "        last_win = max([y for y in all_wins[code] if y < year], default=1955)\n",
    "      \n",
    "      # Count the number of competitions since the last win. Note that the 2020\n",
    "      # contest was cancelled.\n",
    "      comps = year - last_win - 1\n",
    "      if year > 2020 and last_win < 2020:\n",
    "        comps = comps - 1\n",
    "\n",
    "      return comps\n",
    "\n",
    "# Some quick tests.\n",
    "assert(comps_without_win(\"UA\", 2023) == 0)   # won in 2022\n",
    "assert(comps_without_win(\"GB\", 2023) == 24)  # won in 1997\n",
    "assert(comps_without_win(\"AU\", 2023) == 66)  # never won\n",
    "assert(comps_without_win(\"SE\", 1983) == 8)   # won in 1974\n",
    "assert(comps_without_win(\"SE\", 2019) == 3)   # won in 2015\n",
    "assert(comps_without_win(\"NL\", 2019) == 43)  # won in 1975\n",
    "\n",
    "df_VLGMC['comps_without_win'] = df_VLGMC.apply(lambda row: comps_without_win(row['to_code2'], row['year']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Artist</th>\n",
       "      <th>from_country</th>\n",
       "      <th>to_country</th>\n",
       "      <th>points</th>\n",
       "      <th>total_points</th>\n",
       "      <th>rank</th>\n",
       "      <th>from_code2</th>\n",
       "      <th>from_code3</th>\n",
       "      <th>to_code2</th>\n",
       "      <th>...</th>\n",
       "      <th>Contains_Voting_Language</th>\n",
       "      <th>gender</th>\n",
       "      <th>migration_v2p</th>\n",
       "      <th>population_p</th>\n",
       "      <th>prop_emigrants_v2p</th>\n",
       "      <th>migration_p2v</th>\n",
       "      <th>population_v</th>\n",
       "      <th>prop_emigrants_p2v</th>\n",
       "      <th>migration_pop_year</th>\n",
       "      <th>comps_without_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21305</th>\n",
       "      <td>2022</td>\n",
       "      <td>Konstrakta</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>serbia</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>5.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>RS</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>female</td>\n",
       "      <td>658.0</td>\n",
       "      <td>6899126.0</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>9343.0</td>\n",
       "      <td>67081000.0</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21306</th>\n",
       "      <td>2022</td>\n",
       "      <td>Chanel</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>spain</td>\n",
       "      <td>8</td>\n",
       "      <td>282</td>\n",
       "      <td>3.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>ES</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>female</td>\n",
       "      <td>303193.0</td>\n",
       "      <td>47365655.0</td>\n",
       "      <td>0.006401</td>\n",
       "      <td>150892.0</td>\n",
       "      <td>67081000.0</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21307</th>\n",
       "      <td>2022</td>\n",
       "      <td>Cornelia Jakobs</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>sweden</td>\n",
       "      <td>10</td>\n",
       "      <td>245</td>\n",
       "      <td>4.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>female</td>\n",
       "      <td>29715.0</td>\n",
       "      <td>10353442.0</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>35824.0</td>\n",
       "      <td>67081000.0</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21308</th>\n",
       "      <td>2022</td>\n",
       "      <td>Marius Bear</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>switzerland</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>18.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>CH</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>male</td>\n",
       "      <td>45951.0</td>\n",
       "      <td>8638167.0</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>23649.0</td>\n",
       "      <td>67081000.0</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21309</th>\n",
       "      <td>2022</td>\n",
       "      <td>Kalush Orchestra</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>7</td>\n",
       "      <td>379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>UA</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22119.0</td>\n",
       "      <td>67081000.0</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year            Artist    from_country   to_country  points  \\\n",
       "21305  2022        Konstrakta  united kingdom       serbia       0   \n",
       "21306  2022            Chanel  united kingdom        spain       8   \n",
       "21307  2022   Cornelia Jakobs  united kingdom       sweden      10   \n",
       "21308  2022       Marius Bear  united kingdom  switzerland       0   \n",
       "21309  2022  Kalush Orchestra  united kingdom      ukraine       7   \n",
       "\n",
       "       total_points  rank from_code2 from_code3 to_code2  ...  \\\n",
       "21305           169   5.0         GB        GBR       RS  ...   \n",
       "21306           282   3.0         GB        GBR       ES  ...   \n",
       "21307           245   4.0         GB        GBR       SE  ...   \n",
       "21308            28  18.0         GB        GBR       CH  ...   \n",
       "21309           379   1.0         GB        GBR       UA  ...   \n",
       "\n",
       "      Contains_Voting_Language  gender migration_v2p  population_p  \\\n",
       "21305                    False  female         658.0     6899126.0   \n",
       "21306                     True  female      303193.0    47365655.0   \n",
       "21307                     True  female       29715.0    10353442.0   \n",
       "21308                     True    male       45951.0     8638167.0   \n",
       "21309                    False   group           NaN           NaN   \n",
       "\n",
       "       prop_emigrants_v2p  migration_p2v  population_v  prop_emigrants_p2v  \\\n",
       "21305            0.000095         9343.0    67081000.0            0.000139   \n",
       "21306            0.006401       150892.0    67081000.0            0.002249   \n",
       "21307            0.002870        35824.0    67081000.0            0.000534   \n",
       "21308            0.005320        23649.0    67081000.0            0.000353   \n",
       "21309                 NaN        22119.0    67081000.0            0.000330   \n",
       "\n",
       "       migration_pop_year comps_without_win  \n",
       "21305              2020.0                13  \n",
       "21306              2020.0                51  \n",
       "21307              2020.0                 5  \n",
       "21308              2020.0                32  \n",
       "21309              2020.0                 4  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VLGMC.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Border data\n",
    "\n",
    "Raw data is obtained from GeoDataSource: https://github.com/geodatasource/country-borders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_border_code</th>\n",
       "      <th>country_border_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>FR</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>ES</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>OM</td>\n",
       "      <td>Oman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>SA</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>CN</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_code          country_name country_border_code country_border_name\n",
       "0           AD               Andorra                  FR              France\n",
       "1           AD               Andorra                  ES               Spain\n",
       "2           AE  United Arab Emirates                  OM                Oman\n",
       "3           AE  United Arab Emirates                  SA        Saudi Arabia\n",
       "4           AF           Afghanistan                  CN               China"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border = pd.read_csv('../../data/geodatasource-country-borders.csv')\n",
    "border.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the data first; subset to only Eurovision countries\n",
    "ev_code2s = set(df_VLGMC['from_code2'].unique()).union(set(df_VLGMC['to_code2'].unique()))\n",
    "border = border[(border['country_code'].isin(ev_code2s)) & (border['country_border_code'].isin(ev_code2s))]\n",
    "\n",
    "# Generate a list of tuples\n",
    "border_tuples = list(border[['country_code', 'country_border_code']].itertuples(index=False, name=None))\n",
    "# Sanity check to make sure the list is symmetric. Expect True.\n",
    "all((b, a) in border_tuples for a, b in border_tuples)\n",
    "\n",
    "# Yugoslavia needs a manual exception. For now, Yugoslavia shares a border with \n",
    "# country X if X shares a border with either Serbia or Montenegro.\n",
    "def has_border(cty1, cty2):\n",
    "    if cty1 == 'YU':\n",
    "        return has_border('RS', cty2) or has_border('ME', cty2)\n",
    "    elif cty2 == 'YU':\n",
    "        return has_border(cty1, 'RS') or has_border(cty1, 'ME')\n",
    "    else:\n",
    "        return (cty1, cty2) in border_tuples\n",
    "# TODO: CHECK IF THIS IS HISTORICALLY CORRECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_border('BA', 'YU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Artist</th>\n",
       "      <th>from_country</th>\n",
       "      <th>to_country</th>\n",
       "      <th>points</th>\n",
       "      <th>total_points</th>\n",
       "      <th>rank</th>\n",
       "      <th>from_code2</th>\n",
       "      <th>from_code3</th>\n",
       "      <th>to_code2</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>migration_v2p</th>\n",
       "      <th>population_p</th>\n",
       "      <th>prop_emigrants_v2p</th>\n",
       "      <th>migration_p2v</th>\n",
       "      <th>population_v</th>\n",
       "      <th>prop_emigrants_p2v</th>\n",
       "      <th>migration_pop_year</th>\n",
       "      <th>comps_without_win</th>\n",
       "      <th>has_border</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>Danijela</td>\n",
       "      <td>belgium</td>\n",
       "      <td>croatia</td>\n",
       "      <td>5</td>\n",
       "      <td>131</td>\n",
       "      <td>5.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>HR</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>205.0</td>\n",
       "      <td>4620030.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>72.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>Michael Hajiyanni</td>\n",
       "      <td>belgium</td>\n",
       "      <td>cyprus</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>11.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>CY</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>92.0</td>\n",
       "      <td>862418.0</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>Koit Toome</td>\n",
       "      <td>belgium</td>\n",
       "      <td>estonia</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>12.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>EE</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1436634.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>Vlado Janevski</td>\n",
       "      <td>belgium</td>\n",
       "      <td>north macedonia</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>19.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>MK</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>Edea</td>\n",
       "      <td>belgium</td>\n",
       "      <td>finland</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>15.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>FI</td>\n",
       "      <td>...</td>\n",
       "      <td>group</td>\n",
       "      <td>144.0</td>\n",
       "      <td>5107790.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1998</td>\n",
       "      <td>Marie Line</td>\n",
       "      <td>belgium</td>\n",
       "      <td>france</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>FR</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>132113.0</td>\n",
       "      <td>59543659.0</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>123438.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.012177</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1998</td>\n",
       "      <td>Guildo Horn feat. Die Orthopädischen Strümpfe</td>\n",
       "      <td>belgium</td>\n",
       "      <td>germany</td>\n",
       "      <td>7</td>\n",
       "      <td>86</td>\n",
       "      <td>7.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>DE</td>\n",
       "      <td>...</td>\n",
       "      <td>group</td>\n",
       "      <td>22307.0</td>\n",
       "      <td>81678051.0</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>65226.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998</td>\n",
       "      <td>Thalassa</td>\n",
       "      <td>belgium</td>\n",
       "      <td>greece</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>20.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>GR</td>\n",
       "      <td>...</td>\n",
       "      <td>group</td>\n",
       "      <td>4916.0</td>\n",
       "      <td>10562153.0</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>18488.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1998</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>belgium</td>\n",
       "      <td>hungary</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>HU</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>601.0</td>\n",
       "      <td>10328965.0</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1998</td>\n",
       "      <td>Dawn Martin</td>\n",
       "      <td>belgium</td>\n",
       "      <td>ireland</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>IE</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>507.0</td>\n",
       "      <td>3608841.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1998</td>\n",
       "      <td>Dana International</td>\n",
       "      <td>belgium</td>\n",
       "      <td>israel</td>\n",
       "      <td>10</td>\n",
       "      <td>172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>IL</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>4294.0</td>\n",
       "      <td>5545000.0</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>4018.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1998</td>\n",
       "      <td>Chiara</td>\n",
       "      <td>belgium</td>\n",
       "      <td>malta</td>\n",
       "      <td>8</td>\n",
       "      <td>165</td>\n",
       "      <td>3.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>MT</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>377419.0</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>258.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1998</td>\n",
       "      <td>Lars A. Fredriksen</td>\n",
       "      <td>belgium</td>\n",
       "      <td>norway</td>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>NO</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>818.0</td>\n",
       "      <td>4359184.0</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>978.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1998</td>\n",
       "      <td>Sixteen</td>\n",
       "      <td>belgium</td>\n",
       "      <td>poland</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>17.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>PL</td>\n",
       "      <td>...</td>\n",
       "      <td>group</td>\n",
       "      <td>3395.0</td>\n",
       "      <td>38594998.0</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>6931.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1998</td>\n",
       "      <td>Alma Lusa</td>\n",
       "      <td>belgium</td>\n",
       "      <td>portugal</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>13.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>PT</td>\n",
       "      <td>...</td>\n",
       "      <td>group</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>10026176.0</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>16854.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1998</td>\n",
       "      <td>Mălina Olinescu</td>\n",
       "      <td>belgium</td>\n",
       "      <td>romania</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>RO</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>254.0</td>\n",
       "      <td>22684270.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>2714.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1998</td>\n",
       "      <td>Katarína Hasprová</td>\n",
       "      <td>belgium</td>\n",
       "      <td>slovakia</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>SK</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>259.0</td>\n",
       "      <td>5361999.0</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>106.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1998</td>\n",
       "      <td>Vili Resnik</td>\n",
       "      <td>belgium</td>\n",
       "      <td>slovenia</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>18.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>SI</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1989872.0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1998</td>\n",
       "      <td>Mikel Herzog</td>\n",
       "      <td>belgium</td>\n",
       "      <td>spain</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>16.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>ES</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>20333.0</td>\n",
       "      <td>39724050.0</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>38946.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1998</td>\n",
       "      <td>Jill Johnson</td>\n",
       "      <td>belgium</td>\n",
       "      <td>sweden</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>10.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>8826939.0</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>2712.0</td>\n",
       "      <td>10136811.0</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    year                                         Artist from_country  \\\n",
       "0   1998                                       Danijela      belgium   \n",
       "1   1998                              Michael Hajiyanni      belgium   \n",
       "2   1998                                     Koit Toome      belgium   \n",
       "3   1998                                 Vlado Janevski      belgium   \n",
       "4   1998                                           Edea      belgium   \n",
       "5   1998                                     Marie Line      belgium   \n",
       "6   1998  Guildo Horn feat. Die Orthopädischen Strümpfe      belgium   \n",
       "7   1998                                       Thalassa      belgium   \n",
       "8   1998                                        Charlie      belgium   \n",
       "9   1998                                    Dawn Martin      belgium   \n",
       "10  1998                             Dana International      belgium   \n",
       "11  1998                                         Chiara      belgium   \n",
       "12  1998                             Lars A. Fredriksen      belgium   \n",
       "13  1998                                        Sixteen      belgium   \n",
       "14  1998                                      Alma Lusa      belgium   \n",
       "15  1998                                Mălina Olinescu      belgium   \n",
       "16  1998                              Katarína Hasprová      belgium   \n",
       "17  1998                                    Vili Resnik      belgium   \n",
       "18  1998                                   Mikel Herzog      belgium   \n",
       "19  1998                                   Jill Johnson      belgium   \n",
       "\n",
       "         to_country  points  total_points  rank from_code2 from_code3  \\\n",
       "0           croatia       5           131   5.0         BE        BEL   \n",
       "1            cyprus       2            37  11.0         BE        BEL   \n",
       "2           estonia       0            36  12.0         BE        BEL   \n",
       "3   north macedonia       0            16  19.0         BE        BEL   \n",
       "4           finland       0            22  15.0         BE        BEL   \n",
       "5            france       0             3  24.0         BE        BEL   \n",
       "6           germany       7            86   7.0         BE        BEL   \n",
       "7            greece       0            12  20.0         BE        BEL   \n",
       "8           hungary       0             4  23.0         BE        BEL   \n",
       "9           ireland       0            64   9.0         BE        BEL   \n",
       "10           israel      10           172   1.0         BE        BEL   \n",
       "11            malta       8           165   3.0         BE        BEL   \n",
       "12           norway       4            79   8.0         BE        BEL   \n",
       "13           poland       0            19  17.0         BE        BEL   \n",
       "14         portugal       1            36  13.0         BE        BEL   \n",
       "15          romania       0             6  22.0         BE        BEL   \n",
       "16         slovakia       0             8  21.0         BE        BEL   \n",
       "17         slovenia       0            17  18.0         BE        BEL   \n",
       "18            spain       3            21  16.0         BE        BEL   \n",
       "19           sweden       0            53  10.0         BE        BEL   \n",
       "\n",
       "   to_code2  ...  gender migration_v2p population_p  prop_emigrants_v2p  \\\n",
       "0        HR  ...  female         205.0    4620030.0            0.000044   \n",
       "1        CY  ...    male          92.0     862418.0            0.000107   \n",
       "2        EE  ...    male           0.0    1436634.0            0.000000   \n",
       "3        MK  ...    male           NaN          NaN                 NaN   \n",
       "4        FI  ...   group         144.0    5107790.0            0.000028   \n",
       "5        FR  ...  female      132113.0   59543659.0            0.002219   \n",
       "6        DE  ...   group       22307.0   81678051.0            0.000273   \n",
       "7        GR  ...   group        4916.0   10562153.0            0.000465   \n",
       "8        HU  ...    male         601.0   10328965.0            0.000058   \n",
       "9        IE  ...  female         507.0    3608841.0            0.000140   \n",
       "10       IL  ...  female        4294.0    5545000.0            0.000774   \n",
       "11       MT  ...  female          23.0     377419.0            0.000061   \n",
       "12       NO  ...    male         818.0    4359184.0            0.000188   \n",
       "13       PL  ...   group        3395.0   38594998.0            0.000088   \n",
       "14       PT  ...   group        2120.0   10026176.0            0.000211   \n",
       "15       RO  ...  female         254.0   22684270.0            0.000011   \n",
       "16       SK  ...  female         259.0    5361999.0            0.000048   \n",
       "17       SI  ...    male         239.0    1989872.0            0.000120   \n",
       "18       ES  ...    male       20333.0   39724050.0            0.000512   \n",
       "19       SE  ...  female        1119.0    8826939.0            0.000127   \n",
       "\n",
       "    migration_p2v  population_v  prop_emigrants_p2v  migration_pop_year  \\\n",
       "0            72.0    10136811.0            0.000007              1995.0   \n",
       "1            77.0    10136811.0            0.000008              1995.0   \n",
       "2            57.0    10136811.0            0.000006              1995.0   \n",
       "3           120.0    10136811.0            0.000012              1995.0   \n",
       "4          1541.0    10136811.0            0.000152              1995.0   \n",
       "5        123438.0    10136811.0            0.012177              1995.0   \n",
       "6         65226.0    10136811.0            0.006435              1995.0   \n",
       "7         18488.0    10136811.0            0.001824              1995.0   \n",
       "8          1593.0    10136811.0            0.000157              1995.0   \n",
       "9          2195.0    10136811.0            0.000217              1995.0   \n",
       "10         4018.0    10136811.0            0.000396              1995.0   \n",
       "11          258.0    10136811.0            0.000025              1995.0   \n",
       "12          978.0    10136811.0            0.000096              1995.0   \n",
       "13         6931.0    10136811.0            0.000684              1995.0   \n",
       "14        16854.0    10136811.0            0.001663              1995.0   \n",
       "15         2714.0    10136811.0            0.000268              1995.0   \n",
       "16          106.0    10136811.0            0.000010              1995.0   \n",
       "17           23.0    10136811.0            0.000002              1995.0   \n",
       "18        38946.0    10136811.0            0.003842              1995.0   \n",
       "19         2712.0    10136811.0            0.000268              1995.0   \n",
       "\n",
       "    comps_without_win has_border  \n",
       "0                  42      False  \n",
       "1                  42      False  \n",
       "2                  42      False  \n",
       "3                  42      False  \n",
       "4                  42      False  \n",
       "5                  20       True  \n",
       "6                  15       True  \n",
       "7                  42      False  \n",
       "8                  42      False  \n",
       "9                   1      False  \n",
       "10                 18      False  \n",
       "11                 42      False  \n",
       "12                  2      False  \n",
       "13                 42      False  \n",
       "14                 42      False  \n",
       "15                 42      False  \n",
       "16                 42      False  \n",
       "17                 42      False  \n",
       "18                 28      False  \n",
       "19                  6      False  \n",
       "\n",
       "[20 rows x 29 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then just add a new column to df_VLGMC that is True if the two countries are neighbours.\n",
    "\n",
    "df_VLGMCB = df_VLGMC.copy()\n",
    "df_VLGMCB[\"has_border\"] = df_VLGMCB.apply(lambda row: has_border(row['from_code2'], row['to_code2']), axis=1)\n",
    "df_VLGMCB.head(n=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add a row to represent the competition round the votes apply to (which for historical data, is always the final)\n",
    "df_VLGMCB['comp_round'] = 'f'\n",
    "\n",
    "df_VLGMCB.to_csv('../../data/df_main.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the 2023 Performance data \n",
    "\n",
    "\n",
    "This will be used for the purposes of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenderGuess():\n",
    "    \"\"\"Guess the gender of a performer based on entries from Wikidata.\n",
    "    \"\"\"\n",
    "    future = False\n",
    "    exceptions = {\"Brunette\": \"female\"}\n",
    "\n",
    "    def __init__(self, future=False):\n",
    "        print(\"Initialising gender guesser\")\n",
    "        pass\n",
    "\n",
    "    def __search_wikidata(self, string):\n",
    "        \"\"\"\n",
    "        Query the Wikidata API using the wbsearchentities function.\n",
    "        Return the concept ID of the search result that has the musician identifier.\n",
    "        \"\"\"\n",
    "        query = 'https://www.wikidata.org/w/api.php?action=wbsearchentities&search='\n",
    "        query += string\n",
    "        query += '&language=en&format=json'\n",
    "        music_markers = [\n",
    "            'singer', 'artist', 'musician', 'music',\n",
    "            'band', 'group', 'duo', 'ensemble'\n",
    "        ]\n",
    "        res = requests.get(query).json()\n",
    "        if len(res['search']) == 0:\n",
    "            return None\n",
    "\n",
    "        target = 0\n",
    "        for i in range(len(res['search'])):\n",
    "            if 'description' in res['search'][i]['display']:\n",
    "                description = res['search'][i]['display']['description']['value']\n",
    "                if any(markers in description.lower() for markers in music_markers):\n",
    "                    if self.future:\n",
    "                        target = i\n",
    "                        break\n",
    "                    else:\n",
    "                        concept_id = res['search'][i]['id']\n",
    "                        contestant_in = wp.get_property(concept_id, 'P1344')[-1]\n",
    "                        if \"Eurovision\" in contestant_in:\n",
    "                            target = i\n",
    "                            break\n",
    "\n",
    "        return res['search'][target]['id']\n",
    "\n",
    "    def __lookup_gender(self, name):\n",
    "        \"\"\"Find gender of given name. If the name is not related to a wiki entry \n",
    "        it will return 'RNF' (record not found). Alternatively it will return \n",
    "        the gender if the record has one or NA if it does not have this \n",
    "        property.\n",
    "        Args:\n",
    "            name (str): The name to search\n",
    "        Returns:\n",
    "            str: The gender of the person searched\n",
    "        \"\"\"\n",
    "        gender = 'RNF'\n",
    "        data = self.__search_wikidata(name)\n",
    "        if data:\n",
    "            gender = wp.get_property(data, 'P21')[-1]\n",
    "            instance = wp.get_property(data, 'P31')[-1]\n",
    "            if gender == 'NA':\n",
    "                group_checks = [\n",
    "                    \"group\", \"duo\", \"trio\", \"music\", \"band\", \"ensemble\"\n",
    "                ]\n",
    "                if any(x in instance for x in group_checks):\n",
    "                    gender = \"group\"\n",
    "        return gender\n",
    "\n",
    "    def __get_artist_gender(self, search):\n",
    "        if search in self.exceptions:\n",
    "            return self.exceptions[search]\n",
    "\n",
    "        s = requests.Session()\n",
    "        url = \"https://en.wikipedia.org/w/api.php\"\n",
    "        params = {\n",
    "            \"action\": \"opensearch\",\n",
    "            \"namespace\": \"0\",\n",
    "            \"search\": search,\n",
    "            \"limit\": \"10000\",\n",
    "            \"format\": \"json\"\n",
    "        }\n",
    "        r = s.get(url=url, params=params)\n",
    "        names = r.json()[1]\n",
    "        gender = \"\"\n",
    "        if len(names) < 1:\n",
    "            gender = \"RNF\"\n",
    "        else:\n",
    "            for n in names:\n",
    "                gender = self.__lookup_gender(n)\n",
    "                if not any(gender == x for x in [\"RNF\", \"NA\"]):\n",
    "                    return gender\n",
    "        if gender == \"RNF\" or gender == \"NA\":\n",
    "            if (\"&\" in search) or (' and ' in search):\n",
    "                gender = \"group\"\n",
    "        return gender\n",
    "\n",
    "    def guess_gender(self, artist):\n",
    "        \"\"\"Guess the gender of an artist.\n",
    "        Returns a string representing the gender of the artist.\n",
    "        Args:\n",
    "            artist (str): The name of the artist\n",
    "        Returns:\n",
    "            str: One of \"group\", \"female\", \"male\" or \"RNF\"\n",
    "        \"\"\"\n",
    "        gender = self.__get_artist_gender(artist)\n",
    "        #print(\"Artist: {}, gender: {}\".format(artist, gender))\n",
    "        return gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['belgium', 'croatia', 'cyprus', 'estonia', 'north macedonia',\n",
       "       'finland', 'france', 'germany', 'greece', 'hungary', 'ireland',\n",
       "       'israel', 'malta', 'norway', 'poland', 'portugal', 'romania',\n",
       "       'slovakia', 'slovenia', 'spain', 'sweden', 'switzerland',\n",
       "       'netherlands', 'turkey', 'united kingdom', 'austria',\n",
       "       'bosnia and herzegovina', 'denmark', 'iceland', 'lithuania',\n",
       "       'latvia', 'russian federation', 'ukraine', 'albania', 'andorra',\n",
       "       'belarus', 'monaco', 'yugoslavia', 'bulgaria',\n",
       "       'moldova, republic of', 'armenia', 'czechia', 'georgia',\n",
       "       'montenegro', 'serbia', 'azerbaijan', 'san marino', 'italy',\n",
       "       'australia'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VLGMCB['from_country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "from wikipeople import wikipeople as wp # use wp to get the gender data as needed.\n",
    "\n",
    "class EurovisionFuture():\n",
    "    \"\"\"Collect together information about acts that might appear in the\n",
    "    Eurovision final, based on their appearance in the semi finals.\n",
    "    \"\"\"\n",
    "    in_file = None\n",
    "    out_file = None\n",
    "    countries = None\n",
    "    result = None\n",
    "    language_map = None\n",
    "    df = None\n",
    "    language_match = None\n",
    "    gender = None\n",
    "\n",
    "    def __init__(self, in_file, out_file):\n",
    "        self.in_file = in_file\n",
    "        self.out_file = out_file\n",
    "\n",
    "        # Don't run if the files aren't present\n",
    "        for file in [in_file,]:\n",
    "            if not file.is_file():\n",
    "                raise FileNotFoundError(f\"file {str(file)} was not found\")\n",
    "\n",
    "        #self.__load_country_codes()\n",
    "        self.__import_existing()\n",
    "        #self.language_match = LanguageMatch(self.country_codes_dict)\n",
    "        self.gender = GenderGuess(future=True)\n",
    "\n",
    "    def __expand_data(self, collected):\n",
    "        \"\"\"Expand the data using a cross join on voting countries.\n",
    "        For each row in the data frame, generate a duplicate for each country\n",
    "        that might vote for it, filling the \"From country\" column with the\n",
    "        voting country.\n",
    "        Args:\n",
    "            collected (pd.DataFrame): the current data to be expanded\n",
    "        Returns:\n",
    "            pd.DataFrame: the existing data expanded with the \"From country\" column\n",
    "        \"\"\"\n",
    "        from_country = pd.DataFrame({\"from_country\": df_VLGMCB['from_country'].unique()})\n",
    "        collected = pd.merge(collected, from_country, how=\"cross\")\n",
    "\n",
    "        collected['from_code2'], collected['from_code3'] = zip(*collected['from_country'].map(get_country_codes))\n",
    "\n",
    "        # Remove rows where country and from_country are the same (self-voting)\n",
    "        collected = collected.drop(collected[collected[\"to_code2\"] == collected[\"from_code2\"]].index)\n",
    "\n",
    "        # Reset the index\n",
    "        collected = collected.reset_index(drop=True)\n",
    "\n",
    "\n",
    "        return collected\n",
    "\n",
    "    def __transfer_existing_data(self, collected):\n",
    "        \"\"\"Transfer data from the historical data frame into the future frame.\n",
    "        Transfers border and migration data from the most recent year for which\n",
    "        it exists in the historical data into the future data frame.\n",
    "        Args:\n",
    "            collected (pd.DataFrame): the current data to be augmented\n",
    "        Returns:\n",
    "            pd.DataFrame: data updated with border and migration details\n",
    "        \"\"\"\n",
    "        # Fill out the has_border entries from existing data\n",
    "        print('Transfering border data')\n",
    "        collected['has_border'] = collected[['to_code2', 'from_code2']].apply(lambda x: self.__get_has_border(x['to_code2'], x['from_code2']), axis=1)\n",
    "\n",
    "        # Fill the voting language data\n",
    "        collected = pd.merge(collected, df_voting_language[['Country_code2', 'Voting_Languages']], left_on='from_code2', right_on='Country_code2', how='left')\n",
    "        collected['Contains_Voting_Language'] = collected.apply(lambda df: len(set(df['Language_sung']).intersection(df['Voting_Languages'].split())) > 0, axis=1)\n",
    "\n",
    "        # Fill out migration data\n",
    "        print('Transfering migration data')\n",
    "        migration_pop_cols = ['migration_v2p', 'prop_emigrants_v2p', 'migration_p2v',\n",
    "       'population_v', 'prop_emigrants_p2v', 'migration_pop_year']\n",
    "\n",
    "        collected[migration_pop_cols] = collected[['to_code2', 'from_code2']].apply(lambda x: self.__get_migration(x['to_code2'], x['from_code2']), axis=1)\n",
    "        \n",
    "        collected['points'] = np.nan\n",
    "        collected['total_points'] = np.nan\n",
    "        collected['rank'] = np.nan\n",
    "\n",
    "        print(collected['to_code2'].unique())\n",
    "\n",
    "        return collected\n",
    "\n",
    "    def __get_has_border(self, code, from_country):\n",
    "        \"\"\"Check whether there's a land border bertween two countries\n",
    "        Args:\n",
    "            code (str): the country code of one country\n",
    "            from_country (str): the country code of another country\n",
    "        Returns:\n",
    "            iot: True if the countries share a land border, False otherwise\n",
    "        \"\"\"\n",
    "        result = self.df[(self.df['to_code2'] == code) & (self.df['from_code2'] == from_country)].nlargest(1, 'year')['has_border'].values\n",
    "        return result[0] if len(result) > 0 else False\n",
    "\n",
    "    def __get_migration(self, code, from_country):\n",
    "        \"\"\"Get migration data from one countrhy to another\n",
    "        Args:\n",
    "            code (str): the country code for migrating to\n",
    "            from_country (str): the country code for migraition from\n",
    "        Returns:\n",
    "            [band, year, count, prop]: a list containing respectively the migration band (year), the year the data relates to\n",
    "                                       the number of migratnts and the proportion of population of the country migrating from\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        migration_pop_cols = ['migration_v2p', 'prop_emigrants_v2p', 'migration_p2v',\n",
    "       'population_v', 'prop_emigrants_p2v', 'migration_pop_year']\n",
    "\n",
    "        result = self.df[(self.df['to_code2'] == code) & (self.df['from_code2'] == from_country)].nlargest(1, 'year')[migration_pop_cols].values\n",
    "        result = result[0] if len(result) > 0 else [0] * len(migration_pop_cols)\n",
    "        return pd.Series(result)#, index=[migration_pop_cols])\n",
    "\n",
    "    def __get_population(self, code):\n",
    "        \"\"\"Get the most recent population info for a country\n",
    "        Args:\n",
    "            code (str): the country code for the country to check\n",
    "        Returns:\n",
    "            int: population data for the country for the most recent year found in the historical data frame\n",
    "        \"\"\"\n",
    "        result = self.df[self.df['to_code2'] == code][['year', 'population_p']].nlargest(1, 'year')['population_p'].values\n",
    "        return result[0] if len(result) > 0 else 0\n",
    "    \n",
    "    def process(self, explode):\n",
    "        \"\"\"Process the data\n",
    "        Downloads and processes the data for the semi finals in order to \n",
    "        generate data for the finals.\n",
    "        \n",
    "        If the explode parameter is set to True, the output will contain multiple rows for each\n",
    "        country, one for each voting country. If set to False, each country will have only a\n",
    "        single row.\n",
    "        \n",
    "        Args:\n",
    "            explode (bool): set to True to multiply the rows up by voting countries, False otherwise\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the performance data\n",
    "        semi_final_1 = self.__import_participants_from_wiki(2023, 'Semi-final_1', 'sf1')\n",
    "        semi_final_2 = self.__import_participants_from_wiki(2023, 'Semi-final_2', 'sf2')\n",
    "        semi_final_3 = self.__import_participants_from_wiki(2023, 'Final', 'f')\n",
    "        semi_finals = pd.concat([semi_final_1, semi_final_2, semi_final_3])\n",
    "\n",
    "        # Populate the vote-performance data\n",
    "        if explode:\n",
    "            semi_finals = self.__expand_data(semi_finals)\n",
    "            semi_finals = self.__transfer_existing_data(semi_finals)\n",
    "        else:\n",
    "            # Clear the columns that don't make sense without a \"from_country\" voter\n",
    "            for column in ['from_country', 'points', 'total_points', 'rank', 'from_code2', 'from_code3', \n",
    "                           'migration_v2p', 'prop_emigrants_v2p', 'migration_p2v', 'has_border',\n",
    "                           'migration_pop_year', 'prop_emigrants_p2v', 'population_v']:\n",
    "                semi_finals[column] = np.nan\n",
    "\n",
    "        # if any df_VLGMCB columns are not in semi-finals, raise an exception\n",
    "        if len(set(df_VLGMCB.columns) - set(semi_finals.columns)) > 0:\n",
    "            raise Exception(\"Missing columns in semi_finals:\", set(df_VLGMCB.columns) - set(semi_finals.columns))\n",
    "\n",
    "        # Match columns\n",
    "        semi_finals = semi_finals[df_VLGMCB.columns]\n",
    "\n",
    "        # Store the result\n",
    "        self.result = semi_finals\n",
    "\n",
    "    def get_result(self):\n",
    "        \"\"\"Get the result of all that processing\n",
    "        As long as processing has been performed, this will return a data frame of data for the\n",
    "        acts that are likely to appear in the Eurovision final based on their appearance in the\n",
    "        semi finals.\n",
    "        Args:\n",
    "            None\n",
    "        Returns:\n",
    "            pd.DataFrame: the processed data\n",
    "        \"\"\"\n",
    "        return self.result\n",
    "\n",
    "    def __import_existing(self):\n",
    "        \"\"\"\n",
    "        Import the 1998-2022 data set. We need it later do copy some data into the 2023 rows.\n",
    "        Args:\n",
    "            None\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Read in CSV\n",
    "        self.df = pd.read_csv(self.in_file)\n",
    "        self.df['has_border'] = self.df['has_border'].fillna(0)\n",
    "\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "\n",
    "    def __last_win(self, country, year):\n",
    "        \"\"\"Returns the number of years since the last win\n",
    "        Returns the number of years since the last win based on the historical data.\n",
    "        This does not get updated for the most recent winner.\n",
    "        Args:\n",
    "            country (str): the country code for the country to get the info for\n",
    "            year (int): the current year\n",
    "        Returns:\n",
    "            int: the number of years since the country last won\n",
    "        \"\"\"\n",
    "        result = self.df[self.df['to_code2'] == country][['year', 'comps_without_win']].nlargest(1, 'year').values\n",
    "        recent_year, duration = result[0] if len(result) > 0 else [0, 0] \n",
    "        # We're going to assume year > recent_year to make our lives easier\n",
    "        assert(year > recent_year)\n",
    "        return duration + (year - recent_year)\n",
    "\n",
    "    def __import_participants_from_wiki(self, year, header_id, comp_round):\n",
    "        \"\"\"Download the data from the wiki for a particular semi final\n",
    "        Downloads artist data from Wikipedia based on the year and the subheading anchor.\n",
    "        Data is scraped from the first table in the section with the anchor tag or id provided.\n",
    "        Args:\n",
    "            year (int): the year to get the data for\n",
    "            header_id (str): the anchor for the section to scrapte the table data from\n",
    "        \"\"\"\n",
    "        url=f\"https://en.wikipedia.org/wiki/Eurovision_Song_Contest_{year}\"\n",
    "        print('Downloading wikipedia page: {}'.format(url))\n",
    "        response=requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        tables = soup.find_all('table',{'class':\"wikitable\"})\n",
    "\n",
    "        table = soup.find(id=header_id).find_all_next('table')[0]\n",
    "\n",
    "        df_table=pd.read_html(str(table))\n",
    "        df_table=pd.DataFrame(df_table[0])\n",
    "\n",
    "        # Remove citations references from the column titles\n",
    "        df_table.columns = [x.split('[')[0] for x in df_table.columns]\n",
    "\n",
    "        # These values are the same for every row\n",
    "        df_table['year'] = year\n",
    "\n",
    "        # Country codes\n",
    "        df_table['to_country'] = df_table['Country'].str.lower()\n",
    "        df_table['to_country'] = df_table['to_country'].map(standardise_country)\n",
    "        df_table['to_code2'], df_table['to_code3'] = zip(*df_table['to_country'].map(get_country_codes))\n",
    "\n",
    "        # Convert the entry to a list of languages and strip any citation references\n",
    "        print('Deriving language entries')\n",
    "        df_table['Language_sung'] = df_table['Language(s)'].apply(lambda x: [y.lower().split('[')[0] for y in x.split(', ')])\n",
    "        df_table['Contains_English'] = df_table['Language_sung'].apply(lambda x: 'english' in x)\n",
    "        df_table['Contains_NonEnglish'] = df_table['Language_sung'].apply(lambda x: x != ['english'])\n",
    "\n",
    "        # print any countries in songs['Country'] that are not in df_languages['Country/Region']\n",
    "        if len(set(songs['Country_code2']) - set(df_languages['Country_code2'])) > 0: \n",
    "            countries = list(set(songs['Country_code2']) - set(df_languages['Country_code2']))\n",
    "            raise KeyError(\"Country name \" + ', '.join(countries) + \" was in songs, but not in df_languages.\")\n",
    "\n",
    "        # merge df_languages and language on Country and Country/Region\n",
    "        df_table = pd.merge(df_table, df_languages[['Country_code2', 'Official_languages']], left_on='to_code2', right_on='Country_code2', how='left')\n",
    "        \n",
    "        # Tidy the languages column\n",
    "        df_table['Official_languages'] = df_table['Official_languages'].fillna(' ')\n",
    "        df_table['Contains_Multiple_Languages'] = df_table['Language_sung'].apply(lambda x: len(x) > 1)\n",
    "        df_table['Number_of_Languages'] = df_table['Language_sung'].apply(get_n_languages)\n",
    "        df_table['Contains_Own_Language'] = df_table.apply(lambda df: len(set(df['Language_sung']).intersection(df['Official_languages'].split())) > 0, axis=1)\n",
    "\n",
    "\n",
    "        # Figure out the gender from Wikipedia\n",
    "        print('Guessing genders')\n",
    "        df_table['gender'] = df_table['Artist'].apply(lambda x: self.gender.guess_gender(x))\n",
    "\n",
    "        # Copy over data from the existing dataset\n",
    "        print('Transfering population data')\n",
    "        df_table['population_p'] = df_table['to_code2'].apply(lambda x: self.__get_population(x))\n",
    "\n",
    "        print('Calculating last win')\n",
    "        df_table['comps_without_win'] = df_table['to_code2'].apply(lambda x: self.__last_win(x, year))\n",
    "        \n",
    "        # Add in the competition round data\n",
    "        df_table['comp_round'] = comp_round\n",
    "\n",
    "        # Add in the competition round data\n",
    "        df_table['comp_round'] = comp_round\n",
    "\n",
    "        return df_table\n",
    "\n",
    "    def save(self, out_file):\n",
    "        \"\"\"Save the result to a CSV file\n",
    "        \"\"\"\n",
    "        print(\"Writing out results to: {}\".format(out_file))\n",
    "        self.result.to_csv(out_file)\n",
    "\n",
    "def print_syntax():\n",
    "\tprint('Syntax: get_future_performers.py <input-file> <country-pickle> <out-file>')\n",
    "\tprint()\n",
    "\tprint('\\tCollect data about future Eurovision performers')\n",
    "\tprint('\\t<input-file>     : CSV file containing data for previous years')\n",
    "\tprint('\\t<country-pickle> : pickle file mapping countries to country codes')\n",
    "\tprint('\\t<out-file>       : file to save the output CSV to')\n",
    "\tprint()\n",
    "\tprint('Example usage')\n",
    "\tprint('\\tget_future_performers.py eurovision_merged_covariates_03Feb.csv country_codes_dict.pickle out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical data CSV: ../../data/df_main.csv\n",
      "Out file: ../../data/eurovision_2023.csv\n",
      "Initialising gender guesser\n"
     ]
    }
   ],
   "source": [
    "in_file = Path(\"../../data/df_main.csv\")\n",
    "out_file = Path(\"../../data/eurovision_2023.csv\")\n",
    "\n",
    "print(\"Historical data CSV: {}\".format(in_file))\n",
    "print(\"Out file: {}\".format(out_file))\n",
    "\n",
    "# # Initalise\n",
    "future = EurovisionFuture(in_file, out_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell takes around 2 mins to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading wikipedia page: https://en.wikipedia.org/wiki/Eurovision_Song_Contest_2023\n",
      "Deriving language entries\n",
      "Guessing genders\n",
      "Transfering population data\n",
      "Calculating last win\n",
      "Downloading wikipedia page: https://en.wikipedia.org/wiki/Eurovision_Song_Contest_2023\n",
      "Deriving language entries\n",
      "Guessing genders\n",
      "Transfering population data\n",
      "Calculating last win\n",
      "Downloading wikipedia page: https://en.wikipedia.org/wiki/Eurovision_Song_Contest_2023\n",
      "Deriving language entries\n",
      "Guessing genders\n",
      "Transfering population data\n",
      "Calculating last win\n",
      "Transfering border data\n",
      "Transfering migration data\n",
      "['NO' 'MT' 'RS' 'LV' 'PT' 'IE' 'HR' 'CH' 'IL' 'MD' 'SE' 'AZ' 'CZ' 'NL'\n",
      " 'FI' 'DK' 'AM' 'RO' 'EE' 'BE' 'CY' 'IS' 'GR' 'PL' 'SI' 'GE' 'SM' 'AT'\n",
      " 'AL' 'LT' 'AU' 'FR' 'DE' 'IT' 'ES' 'UA' 'GB']\n",
      "['NO' 'MT' 'RS' 'LV' 'PT' 'IE' 'HR' 'CH' 'IL' 'MD' 'SE' 'AZ' 'CZ' 'NL'\n",
      " 'FI' 'DK' 'AM' 'RO' 'EE' 'BE' 'CY' 'IS' 'GR' 'PL' 'SI' 'GE' 'SM' 'AT'\n",
      " 'AL' 'LT' 'AU' 'FR' 'DE' 'IT' 'ES' 'UA' 'GB']\n"
     ]
    }
   ],
   "source": [
    "future.process(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Artist</th>\n",
       "      <th>from_country</th>\n",
       "      <th>to_country</th>\n",
       "      <th>points</th>\n",
       "      <th>total_points</th>\n",
       "      <th>rank</th>\n",
       "      <th>from_code2</th>\n",
       "      <th>from_code3</th>\n",
       "      <th>to_code2</th>\n",
       "      <th>...</th>\n",
       "      <th>migration_v2p</th>\n",
       "      <th>population_p</th>\n",
       "      <th>prop_emigrants_v2p</th>\n",
       "      <th>migration_p2v</th>\n",
       "      <th>population_v</th>\n",
       "      <th>prop_emigrants_p2v</th>\n",
       "      <th>migration_pop_year</th>\n",
       "      <th>comps_without_win</th>\n",
       "      <th>has_border</th>\n",
       "      <th>sf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>Alessandra</td>\n",
       "      <td>belgium</td>\n",
       "      <td>norway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BE</td>\n",
       "      <td>BEL</td>\n",
       "      <td>NO</td>\n",
       "      <td>...</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>5379475.0</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>11538604.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>sf1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Alessandra</td>\n",
       "      <td>croatia</td>\n",
       "      <td>norway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HR</td>\n",
       "      <td>HRV</td>\n",
       "      <td>NO</td>\n",
       "      <td>...</td>\n",
       "      <td>4897.0</td>\n",
       "      <td>5379475.0</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>104.0</td>\n",
       "      <td>4047680.0</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>sf1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>Alessandra</td>\n",
       "      <td>cyprus</td>\n",
       "      <td>norway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CY</td>\n",
       "      <td>CYP</td>\n",
       "      <td>NO</td>\n",
       "      <td>...</td>\n",
       "      <td>210.0</td>\n",
       "      <td>5379475.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>196.0</td>\n",
       "      <td>1237537.0</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>sf1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Alessandra</td>\n",
       "      <td>estonia</td>\n",
       "      <td>norway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EE</td>\n",
       "      <td>EST</td>\n",
       "      <td>NO</td>\n",
       "      <td>...</td>\n",
       "      <td>4742.0</td>\n",
       "      <td>5379475.0</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>458.0</td>\n",
       "      <td>1329522.0</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>sf1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>Alessandra</td>\n",
       "      <td>north macedonia</td>\n",
       "      <td>norway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MK</td>\n",
       "      <td>MKD</td>\n",
       "      <td>NO</td>\n",
       "      <td>...</td>\n",
       "      <td>2932.0</td>\n",
       "      <td>5379475.0</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>sf1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>2023</td>\n",
       "      <td>Mae Muller</td>\n",
       "      <td>serbia</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RS</td>\n",
       "      <td>SRB</td>\n",
       "      <td>GB</td>\n",
       "      <td>...</td>\n",
       "      <td>9343.0</td>\n",
       "      <td>67081000.0</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>658.0</td>\n",
       "      <td>6899126.0</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>2023</td>\n",
       "      <td>Mae Muller</td>\n",
       "      <td>azerbaijan</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AZ</td>\n",
       "      <td>AZE</td>\n",
       "      <td>GB</td>\n",
       "      <td>...</td>\n",
       "      <td>2271.0</td>\n",
       "      <td>67081000.0</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>2023</td>\n",
       "      <td>Mae Muller</td>\n",
       "      <td>san marino</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SM</td>\n",
       "      <td>SMR</td>\n",
       "      <td>GB</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67081000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>2023</td>\n",
       "      <td>Mae Muller</td>\n",
       "      <td>italy</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IT</td>\n",
       "      <td>ITA</td>\n",
       "      <td>GB</td>\n",
       "      <td>...</td>\n",
       "      <td>254054.0</td>\n",
       "      <td>67081000.0</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>66500.0</td>\n",
       "      <td>59438851.0</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>2023</td>\n",
       "      <td>Mae Muller</td>\n",
       "      <td>australia</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "      <td>GB</td>\n",
       "      <td>...</td>\n",
       "      <td>140235.0</td>\n",
       "      <td>67081000.0</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>1285149.0</td>\n",
       "      <td>25655289.0</td>\n",
       "      <td>0.050093</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1776 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year      Artist     from_country      to_country  points  total_points  \\\n",
       "0     2023  Alessandra          belgium          norway     NaN           NaN   \n",
       "1     2023  Alessandra          croatia          norway     NaN           NaN   \n",
       "2     2023  Alessandra           cyprus          norway     NaN           NaN   \n",
       "3     2023  Alessandra          estonia          norway     NaN           NaN   \n",
       "4     2023  Alessandra  north macedonia          norway     NaN           NaN   \n",
       "...    ...         ...              ...             ...     ...           ...   \n",
       "1771  2023  Mae Muller           serbia  united kingdom     NaN           NaN   \n",
       "1772  2023  Mae Muller       azerbaijan  united kingdom     NaN           NaN   \n",
       "1773  2023  Mae Muller       san marino  united kingdom     NaN           NaN   \n",
       "1774  2023  Mae Muller            italy  united kingdom     NaN           NaN   \n",
       "1775  2023  Mae Muller        australia  united kingdom     NaN           NaN   \n",
       "\n",
       "      rank from_code2 from_code3 to_code2  ... migration_v2p population_p  \\\n",
       "0      NaN         BE        BEL       NO  ...        1890.0    5379475.0   \n",
       "1      NaN         HR        HRV       NO  ...        4897.0    5379475.0   \n",
       "2      NaN         CY        CYP       NO  ...         210.0    5379475.0   \n",
       "3      NaN         EE        EST       NO  ...        4742.0    5379475.0   \n",
       "4      NaN         MK        MKD       NO  ...        2932.0    5379475.0   \n",
       "...    ...        ...        ...      ...  ...           ...          ...   \n",
       "1771   NaN         RS        SRB       GB  ...        9343.0   67081000.0   \n",
       "1772   NaN         AZ        AZE       GB  ...        2271.0   67081000.0   \n",
       "1773   NaN         SM        SMR       GB  ...           NaN   67081000.0   \n",
       "1774   NaN         IT        ITA       GB  ...      254054.0   67081000.0   \n",
       "1775   NaN         AU        AUS       GB  ...      140235.0   67081000.0   \n",
       "\n",
       "     prop_emigrants_v2p  migration_p2v  population_v  prop_emigrants_p2v  \\\n",
       "0              0.000351         1195.0    11538604.0            0.000104   \n",
       "1              0.000910          104.0     4047680.0            0.000026   \n",
       "2              0.000039          196.0     1237537.0            0.000158   \n",
       "3              0.000881          458.0     1329522.0            0.000344   \n",
       "4              0.000545            NaN           NaN                 NaN   \n",
       "...                 ...            ...           ...                 ...   \n",
       "1771           0.000139          658.0     6899126.0            0.000095   \n",
       "1772           0.000034            NaN           NaN                 NaN   \n",
       "1773                NaN            NaN           NaN                 NaN   \n",
       "1774           0.003787        66500.0    59438851.0            0.001119   \n",
       "1775           0.002091      1285149.0    25655289.0            0.050093   \n",
       "\n",
       "      migration_pop_year  comps_without_win  has_border   sf  \n",
       "0                 2020.0                 12       False  sf1  \n",
       "1                 2020.0                 12       False  sf1  \n",
       "2                 2020.0                 12       False  sf1  \n",
       "3                 2020.0                 12       False  sf1  \n",
       "4                    NaN                 12       False  sf1  \n",
       "...                  ...                ...         ...  ...  \n",
       "1771              2020.0                 24       False    f  \n",
       "1772                 NaN                 24       False    f  \n",
       "1773                 NaN                 24       False    f  \n",
       "1774              2020.0                 24       False    f  \n",
       "1775              2020.0                 24       False    f  \n",
       "\n",
       "[1776 rows x 30 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "norway                  48\n",
       "belgium                 48\n",
       "iceland                 48\n",
       "greece                  48\n",
       "poland                  48\n",
       "slovenia                48\n",
       "georgia                 48\n",
       "san marino              48\n",
       "austria                 48\n",
       "albania                 48\n",
       "lithuania               48\n",
       "australia               48\n",
       "france                  48\n",
       "germany                 48\n",
       "italy                   48\n",
       "spain                   48\n",
       "ukraine                 48\n",
       "cyprus                  48\n",
       "estonia                 48\n",
       "malta                   48\n",
       "romania                 48\n",
       "serbia                  48\n",
       "latvia                  48\n",
       "portugal                48\n",
       "ireland                 48\n",
       "croatia                 48\n",
       "switzerland             48\n",
       "israel                  48\n",
       "moldova, republic of    48\n",
       "sweden                  48\n",
       "azerbaijan              48\n",
       "czechia                 48\n",
       "netherlands             48\n",
       "finland                 48\n",
       "denmark                 48\n",
       "armenia                 48\n",
       "united kingdom          48\n",
       "Name: to_country, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future.result['to_country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "future.result.to_csv('../../data/df_2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
